[{"id":"33e145189cb2c9be32b78fb749fd41d4","title":"Python爬虫","content":"import requests\nfrom bs4 import BeautifulSoup\nimport re\nimport json\nfrom tqdm import tqdm\n\n\nclass CoronaVirusSpider(object):\n\n    def __init__(self):\n        self.home_url &#x3D; &#39;https:&#x2F;&#x2F;ncov.dxy.cn&#x2F;ncovh5&#x2F;view&#x2F;pneumonia&#39;\n\n    def get_content_from_url(self, url):\n        &quot;&quot;&quot;\n        根据url, 获取响应内容的字符串数据\n        :param url: 请求的URL\n        :return: 响应内容的字符串\n        &quot;&quot;&quot;\n        response &#x3D; requests.get(url)\n        return response.content.decode()\n\n    def parse_home_page(self, home_page, tag_id):\n        &quot;&quot;&quot;\n        解析首页内容,获取解析后的Python数据\n        :param home_page: 首页的内容\n        :return: 解析后的Python数据\n        &quot;&quot;&quot;\n        # 2.从疫情首页,提取最近一日各国疫情数据\n        soup &#x3D; BeautifulSoup(home_page, &#39;html.parser&#39;)\n        script &#x3D; soup.find(id&#x3D;tag_id)\n        text &#x3D; script.text\n        # print(text)\n\n        # 3.从疫情数据中,获取json格式的字符串\n        json_str &#x3D; re.findall(r&#39;\\[.+\\]&#39;, text)[0]\n        # print(json_str)\n\n        # 4.把json格式的字符串转换成Python类型\n        data &#x3D; json.loads(json_str)\n        return data\n\n    def parse_corona_virus(self, last_day_cornoa_virus_of_china, desc):\n        # 定义列表, 用于存储各国从9月1日以来的疫情数据\n        corona_virus &#x3D; []\n        # 2. 遍历各国疫情数据, 获取统计的URL\n        for country in tqdm(last_day_cornoa_virus_of_china, desc):\n\n            # 3. 发送请求, 获取各省疫情json字符串\n            statistics_data_url &#x3D; country[&#39;statisticsData&#39;]\n            statistics_data_json_str &#x3D; self.get_content_from_url(statistics_data_url)\n            # print(statistics_data_json_str)\n\n            # 4.  # 解析各省疫情json字符串, 并添加到列表中\n            statistics_data &#x3D; json.loads(statistics_data_json_str)[&#39;data&#39;]\n            # print(statistics_data)\n            for one_day in statistics_data:\n                one_day[&#39;provinceName&#39;] &#x3D; country[&#39;provinceName&#39;]\n                if country.get(&#39;countryShortCode&#39;):\n                    one_day[&#39;countryShortCode&#39;] &#x3D; country[&#39;countryShortCode&#39;]\n            # print(statistics_data)\n            corona_virus.extend(statistics_data)\n            # print(corona_virus)\n        return corona_virus\n\n    def load(self, path):\n        &quot;&quot;&quot;\n        根据路径, 加载数据\n        :param path:\n        :return:\n        &quot;&quot;&quot;\n        with open(path, encoding&#x3D;&#39;utf-8&#39;) as fp:\n            data &#x3D; json.load(fp)\n        return data\n\n    def save(self, data, path):\n        # 5.把json格式保存,最近一日各国疫情数据\n        with open(path, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;) as fp:\n            json.dump(data, fp, ensure_ascii&#x3D;False)\n\n    def crawl_last_day_corona_virus(self):\n        &quot;&quot;&quot;\n        采集最近一天的各国疫情数据\n        :return:\n        &quot;&quot;&quot;\n        # 1. 发送请求,获取首页内容\n        home_page &#x3D; self.get_content_from_url(self.home_url)\n        # 2. 解析首页内容获取最近一天的各国疫情数据\n        last_day_corona_virus &#x3D; self.parse_home_page(home_page, tag_id&#x3D;&#39;getListByCountryTypeService2true&#39;)\n        # 3. 保存数据\n        self.save(last_day_corona_virus, &#39;..&#x2F;data&#x2F;last_day_corona_virus.json&#39;)\n\n    def crawl_corona_virus(self):\n        &quot;&quot;&quot;\n        采集从9月1日以来各国疫情数据\n        :return:\n        &quot;&quot;&quot;\n        # 1. 加载各国疫情数据\n        last_day_corona_virus &#x3D; self.load(&#39;..&#x2F;data&#x2F;last_day_corona_virus.json&#39;)\n        # print(last_day_corona_virus)\n\n        # 定义列表, 用于存储各国从9月1日以来的疫情数据\n        corona_virus &#x3D; self.parse_corona_virus(last_day_corona_virus, desc&#x3D;&#39;采集9月1日以来的各国疫情信息&#39;)\n\n            # 5. 把列表以json格式保存为文件\n        self.save(corona_virus,&#39;..&#x2F;data&#x2F;corona_virus.json&#39;)\n\n    def crawl_last_day_cornoa_virus_of_china(self):\n        &quot;&quot;&quot;\n        采集最近一日各省疫情数据\n        :return:\n        &quot;&quot;&quot;\n        # 1. 发送请求，获取疫情首页\n        home_page &#x3D; self.get_content_from_url(self.home_url)\n        # 2. 解析疫情首页, 获取最近一日各省份疫情数据\n        last_day_cornoa_virus_of_china &#x3D; self.parse_home_page(home_page,tag_id&#x3D;&#39;getAreaStat&#39;)\n\n        # 3. 保存疫情数据\n        self.save(last_day_cornoa_virus_of_china,&quot;..&#x2F;data&#x2F;last_day_cornoa_virus_of_china.json&quot;)\n\n\n    def crawl_cornoa_virus_of_china(self):\n        &quot;&quot;&quot;\n        采集从9月1日以来的全国个省份的疫情数据\n        :return:\n        &quot;&quot;&quot;\n        # 加载最近一日全国疫情数据\n        last_day_cornoa_virus_of_china &#x3D; self.load(&#39;..&#x2F;data&#x2F;last_day_cornoa_virus_of_china.json&#39;)\n\n        # 遍历最近一日全国疫情数据, 获取各省疫情数据URL\n        corona_virus &#x3D; self.parse_corona_virus(last_day_cornoa_virus_of_china, &#39;采集9月1日以来的各省份疫情信息&#39;)\n\n        # 以json格式保存疫情信息\n        self.save(corona_virus,&#39;..&#x2F;data&#x2F;cornoa_virus_of_china.json&#39;)\n\n\n\n    def run(self):\n        # self.crawl_last_day_corona_virus()\n        self.crawl_corona_virus()\n        # self.crawl_last_day_cornoa_virus_of_china()\n        self.crawl_cornoa_virus_of_china()\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    spider &#x3D; CoronaVirusSpider()\n    spider.run()","slug":"python爬虫","date":"2022-12-10T10:09:28.936Z","categories_index":"Python","tags_index":"Python爬虫","author_index":"Areay7"},{"id":"ee96819a780f88d504f4858a1dcc7bad","title":"Git使用教程","content":"\n\n\n# git 教程\n\n[TOC]\n1.版本管理工具概念我在大学毕业写论文的时候的时候碰到过如下的现象\n&lt;&lt;毕业论文第一版.doc&gt;&gt;\n&lt;&lt;毕业论文第二版.doc&gt;&gt;\n&lt;&lt;毕业论文第三版.doc&gt;&gt;\n&lt;&lt;毕业论文最终版.doc&gt;&gt;\n&lt;&lt;毕业论文最终版2.doc&gt;&gt;\n\n类似的问题我曾经也碰到过很多,例如:\n领导让写文档,写好了,领导让修改,改好了,领导觉得第一版不错,改回来吧,此时内心一脸懵,第一版长啥样没存档啊\n\n实际上,代码开发中也需要这样的软件来管理我们的代码. 例如我们经常会碰到如下的现象:\n改之前好好的,改完就报错了,也没怎么修改啊\n\n在这种情况下如果不能查看修改之前的代码,查找问题是非常困难的.\n如果有一个软件能记录我们对文档的所有修改,所有版本,那么上面的问题讲迎刃而解.而这类软件我们一般叫做版本控制工具\n版本管理工具一般具有如下特性:\n1) 能够记录历史版本,回退历史版本\n2) 团队开发,方便代码合并\n\n\n\n2. 版本管理工具介绍现在比较流行的版本管理工具是git ,但是实际上git 是近几年才发展起来的,可能有一些老的项目,还在用一些老的软件,比如svn\n2.1版本管理发展简史(维基百科) \n2.1.1 SVN(SubVersion)工作流程\nSVN是集中式版本控制系统，版本库是集中放在中央服务器的.\n工作流程如下:\n\t1.从中央服务器远程仓库下载代码\n\t2.修改后将代码提交到中央服务器远程仓库\n\n优缺点:\n优点: 简单,易操作\n缺点:所有代码必须放在中央服务器  \n \t   1.服务器一旦宕机无法提交代码,即容错性较差\n      2.离线无法提交代码,无法及时记录我们的提交行为\n\nsvn流程图\n\n2.1.2 Git工作流程\nGit是分布式版本控制系统（Distributed Version Control System，简称 DVCS），分为两种类型的仓库：\n本地仓库和远程仓库\n工作流程如下\n    1．从远程仓库中克隆或拉取代码到本地仓库(clone&#x2F;pull)\n    2．从本地进行代码修改\n    3．在提交前先将代码提交到暂存区\n    4．提交到本地仓库。本地仓库中保存修改的各个历史版本\n    5．修改完成后，需要和团队成员共享代码时，将代码push到远程仓库\n\n\n总结:git和svn的区别\n1. svn 是集中式版本控制工具,git 是分布式版本控制工具\n2. svn 不支持离线提交,git 支持离线提交代码\n\n3. Git 发展简史 林纳斯·本纳第克特·托瓦兹（Linus Benedict Torvalds, 1969年~ ） \n\n很多人都知道，Linus在1991年创建了开源的Linux，从此，Linux系统不断发展，已经成为最大的服务器系统软件了。\nLinus虽然创建了Linux，但Linux的壮大是靠全世界热心的志愿者参与的，这么多人在世界各地为Linux编写代码，那Linux的代码是如何管理的呢？\n事实是，在2002年以前，世界各地的志愿者把源代码文件通过diff的方式发给Linus，然后由Linus本人通过手工方式合并代码！\n你也许会想，为什么Linus不把Linux代码放到版本控制系统里呢？那个年代不是有CVS、SVN这些免费的版本控制系统吗？因为Linus坚定地反对CVS和SVN，这些集中式的版本控制系统不但速度慢，而且必须联网才能使用。有一些商用的版本控制系统，虽然比CVS、SVN好用，但那是付费的，和Linux的开源精神不符。\n不过，到了2002年，Linux系统已经发展了十年了，代码库之大让Linus很难继续通过手工方式管理了，社区的弟兄们也对这种方式表达了强烈不满，于是Linus选择了一个商业的版本控制系统BitKeeper，BitKeeper的东家BitMover公司出于人道主义精神，授权Linux社区免费使用这个版本控制系统。而授权的前提是:Linux 社区的人不能开发具有相同功能的竞争产品! \n另一方面,BitKeeper不是开源的. 显然与Linux 的开源精神不相符,所以linux 社区的很多人抱怨,不愿意使用.\n典型的就是  Andrew Tridgell  (Samba 开发服务的创造者) 非常不满.偷偷违反了和 BitKeeper 的协议,反编译 BitKeeper 的源代码,开发了个爬虫,然后爬取信息被人发现了. BitKeeper 公司的领导非常不满意,然后开始发布消息说,(下个版本)不再为Linux 提供免费的服务. \nLinus  本人就出面协调(几周或者几个月),但是不管用, 没办法. 估计谈判的过程感觉到了憋屈–”吃人嘴短,拿人手软”\nLinus  本人 花了10天的时间Git 出来了,一个月之内，Linux系统的源码已经由Git管理了！\n \nGit 出来以后毕竟是一个人做的,开始并不好用(刚开始只能用勉强可以用来形容), 还是很多人抱怨,发展了很多年都没有干过其他软件.\n直到 2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub,从此git 迎来了飞速发展,当下git 已经成为了最流行的版本控制工具\n4. Git 的安装4.1 git 的下载下载地址： https://git-scm.com/download\n\n附件\n\n\n## 4.2 安装\n\n\n按照附件的 顺序直接下一步傻瓜式安装即可\n\n其中安装的过程中需要填写一个邮箱和用户名(任意即可)\n\n\n\n\n$\\color{red}{注意: 安装完毕请重启资源管理器,或者重启电脑!!!}$ \n\n更改语言\n\n\n\n5. Git 工作流程5.1 Git 初始化我们先初始化一个本地仓\n1) 新建测试文件夹\n2) 进入文件夹,然后右键创建版本库\n\n\n此时 我们看到 \n1) 文件夹上多了一个绿色图标(如果没有请看本章节 5.3小节说明)\n2) 文件夹内部生成了一个.git 隐藏文件夹(需要设置隐藏文件夹可见)\n\n5.2  git 流程5.2.1 流程图\n5.2.2概念即详解本地仓库：是在开发人员自己电脑上的Git仓库,存放我们的代码(.git 隐藏文件夹就是我们的本地仓库)\t\t\n远程仓库：是在远程服务器上的Git仓库,存放代码(可以是github.com或者gitee.com 上的仓库,或者自己该公司的服务器)\n工作区: 我们自己写代码(文档)的地方\n暂存区: 在 本地仓库中的一个特殊的文件(index) 叫做暂存区,临时存储我们即将要提交的文件\n------------\nClone：克隆，就是将远程仓库复制到本地仓库\nPush：推送，就是将本地仓库代码上传到远程仓库\nPull：拉取，就是将远程仓库代码下载到本地仓库,并将代码 克隆到本地工作区\n\n\n6.Git 的基本使用01-TortoiseGit 操作本地仓库6.1  初始化仓库方法一: \n新建一个文件夹,进入文件夹内部操作\n1)右键--&gt; 在这里创建Git 版本库 \n\n\n  注意: 不要直接在桌面上操作,否则桌面就是一个仓库\n 方法二:\n2) 右键--&gt;Git GUI here\n\n\n方法三: 命令行模式\n2) git init \n\n\n创建完毕仓库,我们发现,此时我们创建的文件夹下有一个.git 文件已经生成了\n并且仓库文件夹上多了一个 绿色图标\n\n6.2 添加文件1)在仓库中新建一个文件\n2)选中新建的文件--&gt;右键--&gt; TortoiseGit--&gt; 添加\n3)此时我们看到文件夹上多了一个 &quot;加号&quot;\n\n\n\n6.3 提交文件至本地仓库1)选中文件\n2) 右键--git提交\n\n\n6.4 修改文件,与再次提交文件当我们修改文件以后,文件上多了一个红色感叹号,表示我们上次提交后该文件被修改过\n提交后文件图标又变成绿色\n\n\n6.5 文件状态讲解Git工作目录下的文件存在两种状态：\n1 untracked 未跟踪（未被纳入版本控制） :  比如新建的文件(此时文件夹上没有图标或者有一个&quot;问号&quot;)\n2 tracked 已跟踪（被纳入版本控制）     \n    2.1 Staged 已暂存状态            : 添加 但未提交状态(此时文件夹上有一个&quot;加号&quot;)\n\t2.2 Unmodified 未修改状态        : 已提交(此时文件夹上有一个&quot;对号&quot;)\n\t2.3 Modified 已修改状态          : 修改了,但是还没有提交 (此时文件夹上有一个&quot;红色感叹号&quot;)\n\n\n这些文件的状态会随着我们执行Git的命令发生变化\n\n6.6 修改文件,不提交和上一个版本比较差异(diff)修改文件,此时不要提交\n选中文件--&gt;右键--&gt; TortoiseGit--&gt; 比较差异\n\n\n6.7 查看提交历史记录选中文件\n右键--&gt; TortoiseGit--&gt; 显示日志\n此时我们可以看到所有的历史提交记录\n\n\n##6.8 回退至历史版本\n右键--&gt; TortoiseGit--&gt; 显示日志\n选中某个版本--&gt; 进行如下操作\n\n\n6.9 文件删除###6.9.1本地删除与恢复\n  1) 直接选中文件删除的话,其实只是删除了本地工作区的文件,并没有删除 仓库中的文件\n   此时时可以回退的, 比如我们进行如下操作\n   1)文件删除\n   2)右键--&gt; TortoiseGit--&gt; 还原\n   此时我们发现文件又被恢复了\n\n\n6.9.2从版本库删除2) 我们如果真的想要将某个文件从服务器删除,需要进行如下操作\n   1) 删除文件,和上面的操作一样\n   2) 提交,此时服务文件已经删除了(历史版本还在,还是可以恢复)\n\n6.9.3从版本库删除,但是不删除本地我们可以如下操作,只删除服务器上的文件,但是本地文件并不删除\n备注: 删除之后需要提交,才会真正的从服务器删除\n\n\n\n\n6.10 忽略提交有时候我们一些文件是不需要提交的比如说idea&#x2F;eclipse 开发的代码自动生成的配置文件\n如何配置不提交呢\n\n\n此时我们的根目录下会生成一个.gitignore 文件\n忽略文件如何阅读,常见格式\n# 所有以.a 结尾的文件讲被忽略(递归)\n*.a\n# 不管其他规则怎样,强制不忽略  lib.a\n!lib.a\n# 只忽略 文件 TODO (注意这里是文件)\n&#x2F;TODO\n# 忽略 build文件夹下所有内容(递归) 这里是文件夹\nbuild&#x2F;\n# 忽略 doc 目录下以 *.txt 结尾的文件 (不递归)\ndoc&#x2F;*.txt\n# 忽略 doc 目录下以 *.pdf 结尾的文件 (递归)\ndoc&#x2F;**&#x2F;*.pdf\n\n当然理解了上述规则,我们也可以手动编辑该文件,而不用通过窗口化操作(如果不嫌麻烦)\n7. Git 的基本使用02-TortoiseGit 操作本地仓库(分支)7.1 分支的概念几乎所有的版本控制系统都以某种形式支持分支。 使用分支意味着你可以把你的工作从开发主线上分离开来，避免影响开发主线。多线程开发,可以同时开启多个任务的开发,多个任务之间互不影响.\n\n7.2 为何要使用分支先看单线程开发\n\n思考如下现象\n    10.1 日 业务部门提出需求 : 明年 元旦3天做2个促销活动\n\t1) 12.31 号上线活动1, \n\t2) 1.4 号上线活动2 ,同时 要求撤销 活动1\n    你所在 部门领导 为了保证能顺利完成,要求 11.15 号完成 上述连个功能的开发工作\n此时作为开发人员:我要面临两个文件, 活动1 的代码,即要存在(12.31 要用)又要不存在(1.4 号要求删除) ,我们怎么做?\n显然比较棘手,如果使用分支(可以理解为将代码复制一份)将很好解决\n\n\n7.3 创建分支到现在为止,我们一直使用的时主分支(master)\n在主分支上操作创建分支\n\n\n7.4 分支的查看切换7.4.1查看分支查看版本分支图,此时我们看到有两个分支\n当然,我们可以创建多个分支\n可以看到多个分支的图形\n\n\n7.4.2切换分支右键--&gt; 检出\n\n\n\n\n##7.5 分支的合并与删除\n7.5.1合并我们将代码切换到分支1,然后写属于需求1 的代码并提交\n当我们把需求1 开发完毕如何把需求1 的代码合并到主分支呢?\n--&gt;1 切换到 主版本\n--&gt;2 右键 合并即可将需求1 写的代码合并至主分支\n-----此时我们看到代码自动合并到了master分支\n\n\n7.5.2删除分支\n5,冲突的处理​\t5.1)冲突的概念\n现象演示\t\n\t开发人员A 开发需求1,开发了一个工具类 MathUtil,里面第一行写了一个方法 add(int [] args)\n 同时开发人员B 开发需求2,开发了一个工具类 MathUtil,里面第一行写了一个方法 add(int a int b)\n他们在互相不知道对方需求的情况下同时提交了代码到自己的分支\n   思考此时如果我们把需求1 和需求2 同时都合并到主分支上, 主分支的 工具类 MathUtil 的第一行应该使用谁的代码? \n   此时主分支是不能智能判断第一行使用谁的代码,合并时会报错,我们叫做冲突.\n\n\n​\t5.2) 如何处理冲突\n分析一下冲突的原因:\n\t开发人员之间彼此没有沟通导致的同一个时间节点修改了同一个地方的代码,合并是冲突\n思考:\n\t我们能直接把某个开发人员开发的代码删除吗?\n显然不能\n\t所以在处理冲突时,第一步应该时找开发另一个需求的人员沟通,之后才是处理冲突\n-----\n--&gt; 选中冲突的文件(带黄色感叹号的文件都是冲突的文件,如果有多个需要逐一处理)\n--&gt; 右键--&gt; 编辑冲突,\n--&gt;处理完毕后.标记已解决\n\n\n\n8.tag  标签8.1 标签的概念如果你的项目达到一个重要的阶段，并希望永远记住那个特别的提交快照，你可以给它打上标签(tag)\n比如说，我们想为我们的项目发布一个&quot;1.0&quot;版本。 我们给最新一次提交打上（HEAD）&quot;v1.0&quot;的标签。\n标签可以理解为项目里程碑的一个标记,一旦打上了这个标记则,表示当前的代码将不允许提交\n\n8.2  标签的创建(tag)标签的创建和分支的创建操作几乎一样\n\n\n8.3 标签的切换与删除\n\n9. 远程仓库我们的代码不能总是放在本地,因为总是放在本地,一旦电脑出现故障,数据将丢失,怎么共享呢,这里我们需要一个服务器, 我们可以把代码放到服务器上,然后让别人下载,这样我峨嵋你既可以备份代码,也可以进行团队协作开发\n9.0 局域网仓库实际上我们可以搭建一个单间的局域网服务器共享我们的代码\n\n9.0.1本地相对路径,多个文件夹之间共享代码\n9.0.2开启局域网共享代码\n\n局域网这种共享是没有安全控制的,都可以访问,如果想要搭建一个可以控制权限的服务器需要借助第三方软件\ngitblit,可以自行搜索搭建\n9.1 常用远程仓库托管服务除了自己搭建服务器,其实我们可以使用一些免费的远程仓库,远程仓库有很多,常见的免费互联网远程仓库托管服务如下:\nwww.github.com\nwww.gitee.com\nwww.gitlab.com\n\ngithub  是一个基于git实现在线代码托管的仓库，向互联网开放，企业版要收钱。\ngitee    即码云，是 oschina 免费给企业用的，不用自己搭建环境。\ngitlab   类似 github，一般用于在企业内搭建git私服，要自己搭环境。\n\nGitHub(gitee)、GitLab 不同点：\n1、GitHub如果使用私有仓库是需要付费的，(2019年开始私有仓库也是免费的但是只能3个人协同开发,想要更多需要收费)，GitLab可以在上面搭建私人的免费仓库。\n2、GitLab让开发团队对他们的代码仓库拥有更多的控制，相对于GitHub，它有不少的特色：\n    (1)允许免费设置仓库权限\n    (2)允许用户选择分享一个project的部分代码\n    (3)允许用户设置project的获取权限，进一步提升安全性\n    (4)可以设置获取到团队整体的改进进度\n    (5)通过innersourcing让不在权限范围内的人访问不到该资源\n\n\n鉴于国内用户可能网络不好,这里我们使用gitee(码云) 来讲解我们的课程,其他可自行找资料学习非常类似\n9.2  码云账号注册\n填写邮箱发送验证码,然后可以注册账号,主页如下\n\n9.3 创建远程仓库\n\n各个类型仓库之间的区别\n\n\n9.4  把本地代码推送到远端\n\n\n此时我们刷新仓库发现代码已经存在了\n我们填写的用户信息,会被保存在本地,下次提交无需填写用户名和密码\n\n9.5  从远程仓库克隆代码我们同样可以从库下载代码,\n新建一个文件夹 repo2 ,进入然后进行如下操作\n\n此时我们发现我们的代码已经被下载下来了\n9.6  代码的修改与提交,查看历史1)此时我们修改代码就不能仅仅是提交到本地了,提交完毕应该推送到远端服务器\n2)此时如果别人从远端仓库下载最新的代码其实是可以看到我们的代码修改记录的\n   git --&gt;显示日志\n\n\n9.7 ssh 连接概述实际上git 不仅仅支持用户名密码方式的配置,可以有另外一种相对更加安全的配置即ssh 方式配置\n\n ssh 方式的底层原理\nssh连接地城是RAS加密算法,又称非对称加密,是一种现在公认的最安全的加密方式\n数学基础好的同学可以研究一下\nhttps:&#x2F;&#x2F;www.cnblogs.com&#x2F;cjm123&#x2F;p&#x2F;8243424.html\n\n公钥私钥加密可以看作古代 的&quot;虎符&quot; , 我们本地电脑有一份,远程服务器有一份, 只要 &quot;虎符&quot; 核对通过 表示身份无误,可以执行提交等操作,无需输入用户名密码\n\n9.8 ssh 密钥的生成#生成公钥私钥\n ssh-keygen -t rsa\n 一直回车即可\n 会默认用户目录 .ssh 目录生成一个默认的id_rsa文件 和id_rsa.pub\n\n\n\n9.9 ssh 密钥配置\n9.10 ssh 方式克隆&#x2F;提交代码:  配置完成之后我们克隆我们之前的项目\n\n修改后直接提交推送即可成功,,git 会自动去.ssh 目录找我们的私钥进行匹配\n9.11. 远程仓库的其他操作概念\n\n当我们从 gitee 上查看别人的项目的时候我们可能会看到上图中的按钮\n指数:\n\t是gitee 网站根据当前项目的各项指标计算出来的一个值\n\n\nStar:\n\t点赞, 注意这里的并不像朋友圈那样容易获得点赞,圈内人还是很克制的\nWatch:\n   如果你watch 了某个开源项目,那么这个项目后续所有的改动你将收到通知\nFork :\n\t将别人的代码克隆到你自己的仓库\n\t作用一: 如果担心某个优秀的项目别人突然有一天不开源了,你可以fork到自己的仓库\n    作用二: 修改别人的代码\n\t  以linux 为例,你其实不是linux 社区的开发人员,但是你 又想为linux 开发做贡献(维护代码)\n\t   你并没有权限,怎们办?\n\t   你可以先把linux 开源的代码 fork 到你自己的仓库,此时你就可以操作自己的仓库进行修改代码了\n\t   如何让别人合并你修改好的代码呢? \n\t    我们注意项目的上方有一个 &quot; Pull Request&quot; 这个按钮的意思是 &quot;请求求别人合并你修改的代码&quot;\n\t    当我们发起一个 Pull Request 时 , 项目的拥有者将收到 Pull Request请求,然后将根据你提交代码的质量决定是否合并\n\n项目操作\n1)我们可以删除修改我们自己仓库的基本信息\n\n我们可以邀请其他人成为项目的开发人员或者管理人员\n\n\n我们可以删除修改我们自己仓库的基本信息\n\n\n9.12 利用 gitee 搭建个人主页1)将静态资源上传至仓库\n2) 选择服务 pages 即可部署\n注意 1)必须有个index.html 文件\n注意 2) 只能搭建静态网站,动态网站请租赁服务器搭建提供服务\n注意 3) gitee 要求必须绑定手机号\n\n\n\n点击开启后gitee 会自动生成一个域名\n\n直接访问即可\n此时我们已经在git 上部署了一个静态的网站\n\n10.命令行– git基本操作10.1  介绍​\t上述我们的操作 使用的 是客户端TortoiseGit 操作的git ,实际上底层依旧是使用的命令行帮我们执行, 在早期 git 并没有窗口化工具,开发人员只能使用命令行模式\n  实际上,如果你掌握并熟练使用了命令行模式操作git 的话,你会发现某些操作命令行比窗口化操作要简单\n所有你在工作中会发现高深的技术人员可能会喜欢命令行模式提交git\n##10.2 环境配置\n当安装Git后首先要做的事情是设置用户名称和email地址。这是非常重要的，因为每次Git提交都会使用该用户信息\n#设置用户信息 \n   git config --global user.name “itcast”\n   git config --global user.email “itcast@itcast.cn”\n#查看配置信息\n   git config --list\n   git config user.name\n#通过上面的命令设置的信息会保存在~&#x2F;.gitconfig文件中\n\n\n##10.3  初始化本地仓库 init\n# 初始化仓库带工作区\ngit init\n# 如果执行失败(针对github) 可执行一下两个\ngit clone https:&#x2F;&#x2F;github.com&#x2F;hexojs&#x2F;hexo-starter.git .&#x2F;\ncnpm install\n# 初始化仓库不带工作区\ngit init --bare  \n\n##10.4 克隆 clone\n# 从远程仓库克隆\ngit clone 远程Git仓库地址 \n例如: git clone https:&#x2F;&#x2F;gitee.com&#x2F;itcast&#x2F;gittest.git\n\n##10.5  查看状态 status\n# 查看状态\ngit status \n#查看状态 使输出信息更加简洁\ngit status –s \n\n##10.6 add \n# 将未跟踪的文件加入暂存区\ngit add  &lt;文件名&gt;  \n# 将暂存区的文件取消暂存 (取消 add )\ngit reset  &lt;文件名&gt;  \n\n\n##10.7 commit\n# git commit 将暂存区的文件修改提交到本地仓库\ngit commit -m &quot;日志信息&quot;  &lt;文件名&gt;  \n\n\n##10.8 删除 rm\n# 从本地工作区 删除文件\ngit rm &lt;文件名&gt;  \n# 如果本工作区库误删, 想要回退\ngit checkout head &lt;文件名&gt;  \n\n11. 命令行–git 远程仓库操作11.1    查看远程# 查看远程  列出指定的每一个远程服务器的简写\ngit remote \n# 查看远程 , 列出 简称和地址\ngit remote  -v  \n# 查看远程仓库详细地址\ngit remote show  &lt;仓库简称&gt;\n\n\n11.2 添加&#x2F;移除远测仓库# 添加远程仓库\ngit remote add &lt;shortname&gt; &lt;url&gt;\n# 移除远程仓库和本地仓库的关系(只是从本地移除远程仓库的关联关系，并不会真正影响到远程仓库)\ngit remote rm &lt;shortname&gt; \n\n11.3 从远程仓库获取代码# 从远程仓库克隆\ngit clone &lt;url&gt; \n# 从远程仓库拉取 (拉取到.git 目录,不会合并到工作区,工作区发生变化)\ngit fetch  &lt;shortname&gt;  &lt;分支名称&gt;\n# 手动合并  把某个版本的某个分支合并到当前工作区\ngit merge &lt;shortname&gt;&#x2F;&lt;分支名称&gt;\n# 从远程仓库拉取 (拉取到.git 目录,合并到工作区,工作区不发生变化) &#x3D; fetch+merge\ngit pull  &lt;shortname&gt;  &lt;分支名称&gt;\ngit pull  &lt;shortname&gt;  &lt;分支名称&gt;  --allow-unrelated-histories  #  强制拉取合并\n\n注意：如果当前本地仓库不是从远程仓库克隆，而是本地创建的仓库，并且仓库中存在文件，此时再从远程仓库拉取文件的时候会报错（fatal: refusing to merge unrelated histories ），解决此问题可以在git pull命令后加入参数–allow-unrelated-histories (如上 命令)\n# 将本地仓库推送至远程仓库的某个分支\ngit push [remote-name] [branch-name]\n\n12.  命令行– 分支# 默认 分支名称为 master\n# 列出所有本地分支\ngit branch\n# 列出所有远程分支\ngit branch -r\n# 列出所有本地分支和远程分支\ngit branch -a\n# 创建分支\ngit branch &lt;分支名&gt;\n# 切换分支 \ngit checkout &lt;分支名&gt;\n# 删除分支(如果分支已经修改过,则不允许删除)\ngit branch -d  &lt;分支名&gt;\n# 强制删除分支\ngit branch -D  &lt;分支名&gt;\n\n# 提交分支至远程仓库\ngit push &lt;仓库简称&gt; &lt;分支名称&gt;\t\n# 合并分支 将其他分支合并至当前工作区\ngit merge &lt;分支名称&gt;\n# 删除远程仓库分支\ngit push origin –d branchName\n\n13 . 命令行 –tag# 列出所有tag\ngit tag\n# 查看tag详细信息 \ngit show [tagName]\n# 新建一个tag\ngit tag [tagName]\n# 提交指定tag\n$ git push [仓库简称] [tagName]\n# 新建一个分支，指向某个tag\n$ git checkout -b [branch] [tag]\n# 删除本地tag\n$ git tag -d [tag]\n# 删除远程tag (注意 空格)\n$ git push origin :refs&#x2F;tags&#x2F;[tag]\n\n14. 案例企业中我们是如何开发的\n1) 入职第一天,管理人员分配&#x2F;git账号密码 \n2) 开发人员下载代码即文档&#x2F; 根据文档将环境搭建成功\n3) 团队一般会给你讲讲项目相关的支持\n----\n4) 你接到第一个需求(或者某个功能,一般要经过沟通,分析,设计...等过程)\n5) 创建feature分支(一般一个需求对应一个feature,命名格式上标注该需求的id)\n6) 开发需求,本地测试,提交代码到当前需求对应的feature分支,\n\t一般来讲为了避免将测试代码提交,需要提交前,检查如下步骤\n\t6.1) 是否多提交了某个文件,比如测试文件\n\t6.2) 是否漏提交文件\n\t6.3) 打开每一个应该提交的文件,判断是否多提交了一行代码,是否少提交了一行代码,是否删除了本应该存在的代码 \n\t检查完毕提交代码\n7) 合并分支至test分支-- 测试人员会在test分支中测试\n8) 测试人员测试bug ,开发者在feature分支上继续修改,提交\n9) 测试人员测试通过 ,test分支会被测试人员合并到develop开发分支,再次测试\n10)develop分支最终会被合并到master主分支\n\n\n\n\n\n\n\n\n\n\n\n\n&#96;\n","slug":"Git教程","date":"2022-12-08T15:59:32.357Z","categories_index":"Git","tags_index":"Git教程","author_index":"Areay7"},{"id":"01997d5dc8999c6dc19f4a1759fa3505","title":"Mysql笔记","content":"\n未来记Mysql笔记的地方\n\n","slug":"Mysql笔记","date":"2022-12-05T15:19:00.982Z","categories_index":"Mysql","tags_index":"Mysql笔记","author_index":"Areay7"},{"id":"9ca8e0c443e55c2bcc66957374b4114f","title":"Python笔记","content":"\n未来记Python笔记的地方\n\n","slug":"Python笔记","date":"2022-12-05T15:19:00.982Z","categories_index":"Python","tags_index":"Python笔记","author_index":"Areay7"},{"id":"28408cd8616ad6c8e0025468ac5c92e6","title":"Shell脚本笔记","content":"\n未来记Shell脚本笔记的地方\n\n","slug":"Shell脚本","date":"2022-12-05T15:19:00.982Z","categories_index":"Shell脚本","tags_index":"Shell脚本笔记","author_index":"Areay7"},{"id":"0fbcbadfbe7a5ddbd469d48f41caddc9","title":"Linux课程笔记","content":"Linux基础命令Linux的目录结构\n\n/，根目录是最顶级的目录了\nLinux只有一个顶级目录：/\n路径描述的层次关系同样适用/来表示\n&#x2F;home&#x2F;itheima&#x2F;a.txt，表示根目录下的home文件夹内有itheima文件夹，内有a.txt\n\nls命令功能：列出文件夹信息\n语法：ls [-l -h -a] [参数]\n\n参数：被查看的文件夹，不提供参数，表示查看当前工作目录\n-l，以列表形式查看\n-h，配合-l，以更加人性化的方式显示文件大小\n-a，显示隐藏文件\n\n隐藏文件、文件夹在Linux中以.开头的，均是隐藏的。\n默认不显示出来，需要-a选项才可查看到。\npwd命令功能：展示当前工作目录\n语法：pwd\ncd命令功能：切换工作目录\n语法：cd [目标目录]\n参数：目标目录，要切换去的地方，不提供默认切换到当前登录用户HOME目录\nHOME目录每一个用户在Linux系统中都有自己的专属工作目录，称之为HOME目录。\n\n普通用户的HOME目录，默认在：/home/用户名\n\nroot用户的HOME目录，在：/root\n\n\nFinalShell登陆终端后，默认的工作目录就是用户的HOME目录\n相对路径、绝对路径\n相对路径，&#x3D;&#x3D;非&#x3D;&#x3D;/开头的称之为相对路径\n相对路径表示以当前目录作为起点，去描述路径，如test/a.txt，表示当前工作目录内的test文件夹内的a.txt文件\n\n绝对路径，&#x3D;&#x3D;以&#x3D;&#x3D;/开头的称之为绝对路径\n绝对路径从根开始描述路径\n\n\n特殊路径符\n.，表示当前，比如.&#x2F;a.txt，表示当前文件夹内的a.txt文件\n..，表示上级目录，比如../表示上级目录，../../表示上级的上级目录\n~，表示用户的HOME目录，比如cd ~，即可切回用户HOME目录\n\nmkdir命令功能：创建文件夹\n语法：mkdir [-p] 参数\n\n参数：被创建文件夹的路径\n选项：-p，可选，表示创建前置路径\n\ntouch命令功能：创建文件\n语法：touch 参数\n\n参数：被创建的文件路径\n\ncat命令功能：查看文件内容\n语法：cat 参数\n\n参数：被查看的文件路径\n\nmore命令功能：查看文件，可以支持翻页查看\n语法：more 参数\n\n参数：被查看的文件路径\n在查看过程中：\n空格键翻页\nq退出查看\n\n\n\ncp命令功能：复制文件、文件夹\n语法：cp [-r] 参数1 参数2\n\n参数1，被复制的\n参数2，要复制去的地方\n选项：-r，可选，复制文件夹使用\n\n示例：\n\ncp a.txt b.txt，复制当前目录下a.txt为b.txt\ncp a.txt test&#x2F;，复制当前目录a.txt到test文件夹内\ncp -r test test2，复制文件夹test到当前文件夹内为test2存在\n\nmv命令功能：移动文件、文件夹\n语法：mv 参数1 参数2\n\n参数1：被移动的\n参数2：要移动去的地方，参数2如果不存在，则会进行改名\n\nrm命令功能：删除文件、文件夹\n语法：rm [-r -f] 参数...参数\n\n参数：支持多个，每一个表示被删除的，空格进行分隔\n选项：-r，删除文件夹使用\n选项：-f，强制删除，不会给出确认提示，一般root用户会用到\n\n\n\n\n\n\n\n\n\n\nrm命令很危险，一定要注意，特别是切换到root用户的时候。\nwhich命令功能：查看命令的程序本体文件路径\n语法：which 参数\n\n参数：被查看的命令\n\nfind命令功能：搜索文件\n语法1按文件名搜索：find 路径 -name 参数\n\n路径，搜索的起始路径\n参数，搜索的关键字，支持通配符*， 比如：*test表示搜索任意以test结尾的文件\n\ngrep命令功能：过滤关键字\n语法：grep [-n] 关键字 文件路径\n\n选项-n，可选，表示在结果中显示匹配的行的行号。\n参数，关键字，必填，表示过滤的关键字，带有空格或其它特殊符号，建议使用””将关键字包围起来\n参数，文件路径，必填，表示要过滤内容的文件路径，可作为内容输入端口\n\n\n\n\n\n\n\n\n\n\n参数文件路径，可以作为管道符的输入\nwc命令功能：统计\n语法：wc [-c -m -l -w] 文件路径\n\n选项，-c，统计bytes数量\n选项，-m，统计字符数量\n选项，-l，统计行数\n选项，-w，统计单词数量\n参数，文件路径，被统计的文件，可作为内容输入端口\n\n\n\n\n\n\n\n\n\n\n参数文件路径，可作为管道符的输入\n管道符|写法：|\n功能：将符号左边的结果，作为符号右边的输入\n示例：\ncat a.txt | grep itheima，将cat a.txt的结果，作为grep命令的输入，用来过滤itheima关键字\n可以支持嵌套：\ncat a.txt | grep itheima | grep itcast\necho命令功能：输出内容\n语法：echo 参数\n\n参数：被输出的内容\n\n&#96;反引号功能：被两个反引号包围的内容，会作为命令执行\n示例：\n\necho `pwd`，会输出当前工作目录\n\ntail命令功能：查看文件尾部内容\n语法：tail [-f] 参数\n\n参数：被查看的文件\n选项：-f，持续跟踪文件修改\n\nhead命令功能：查看文件头部内容\n语法：head [-n] 参数\n\n参数：被查看的文件\n选项：-n，查看的行数\n\n重定向符功能：将符号左边的结果，输出到右边指定的文件中去\n\n&gt;，表示覆盖输出\n&gt;&gt;，表示追加输出\n\nvi编辑器命令模式快捷键\n\n\n底线命令快捷键\n命令的选项我们学习的一系列Linux命令，它们所拥有的选项都是非常多的。\n比如，简单的ls命令就有：-a -A -b -c -C -d -D -f -F -g -G -h -H -i -I -k -l -L -m -n -N -o -p -q -Q -r-R -s -S -t -T -u -U -v -w -x -X -1等选项，可以发现选项是极其多的。\n课程中， 并不会将全部的选项都进行讲解，否则，一个ls命令就可能讲解2小时之久。\n课程中，会对常见的选项进行讲解， 足够满足绝大多数的学习、工作场景。\n查看命令的帮助可以通过：命令 --help查看命令的帮助手册\n\n查看命令的详细手册可以通过：man 命令查看某命令的详细手册\n\nLinux常用操作软件安装\nCentOS系统使用：\nyum [install remove search] [-y] 软件名称\ninstall 安装\nremove 卸载\nsearch 搜索\n-y，自动确认\n\n\n\n\nUbuntu系统使用\napt [install remove search] [-y] 软件名称\ninstall 安装\nremove 卸载\nsearch 搜索\n-y，自动确认\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyum 和 apt 均需要root权限\nsystemctl功能：控制系统服务的启动关闭等\n语法：systemctl start | stop | restart | disable | enable | status 服务名\n\nstart，启动\nstop，停止\nstatus，查看状态\ndisable，关闭开机自启\nenable，开启开机自启\nrestart，重启\n\n软链接功能：创建文件、文件夹软链接（快捷方式）\n语法：ln -s 参数1 参数2\n\n参数1：被链接的\n参数2：要链接去的地方（快捷方式的名称和存放位置）\n\n日期语法：date [-d] [+格式化字符串]\n\n-d 按照给定的字符串显示日期，一般用于日期计算\n\n格式化字符串：通过特定的字符串标记，来控制显示的日期格式\n\n%Y   年%y   年份后两位数字 (00..99)\n%m   月份 (01..12)\n%d   日 (01..31)\n%H   小时 (00..23)\n%M   分钟 (00..59)\n%S   秒 (00..60)\n%s   自 1970-01-01 00:00:00 UTC 到现在的秒数\n\n\n\n示例：\n\n按照2022-01-01的格式显示日期\n\n\n按照2022-01-01 10:00:00的格式显示日期\n\n\n-d选项日期计算\n\n\n支持的时间标记为：\n\n\n\n\n\n时区修改时区为中国时区\n\nntp功能：同步时间\n安装：yum install -y ntp\n启动管理：systemctl start | stop | restart | status | disable | enable ntpd\n手动校准时间：ntpdate -u ntp.aliyun.com\nip地址格式：a.b.c.d\n\nabcd为0~255的数字\n\n特殊IP：\n\n127.0.0.1，表示本机\n0.0.0.0\n可以表示本机\n也可以表示任意IP（看使用场景）\n\n\n\n查看ip：ifconfig\n主机名功能：Linux系统的名称\n查看：hostname\n设置：hostnamectl set-hostname 主机名\n配置VMware固定IP\n修改VMware网络，参阅PPT，图太多\n\n设置Linux内部固定IP\n修改文件：/etc/sysconfig/network-scripts/ifcfg-ens33\n示例文件内容：\nTYPE&#x3D;&quot;Ethernet&quot;\nPROXY_METHOD&#x3D;&quot;none&quot;\nBROWSER_ONLY&#x3D;&quot;no&quot;\nBOOTPROTO&#x3D;&quot;static&quot;\t\t\t# 改为static，固定IP\nDEFROUTE&#x3D;&quot;yes&quot;\nIPV4_FAILURE_FATAL&#x3D;&quot;no&quot;\nIPV6INIT&#x3D;&quot;yes&quot;\nIPV6_AUTOCONF&#x3D;&quot;yes&quot;\nIPV6_DEFROUTE&#x3D;&quot;yes&quot;\nIPV6_FAILURE_FATAL&#x3D;&quot;no&quot;\nIPV6_ADDR_GEN_MODE&#x3D;&quot;stable-privacy&quot;\nNAME&#x3D;&quot;ens33&quot;\nUUID&#x3D;&quot;1b0011cb-0d2e-4eaa-8a11-af7d50ebc876&quot;\nDEVICE&#x3D;&quot;ens33&quot;\nONBOOT&#x3D;&quot;yes&quot;\nIPADDR&#x3D;&quot;192.168.88.131&quot;\t\t# IP地址，自己设置，要匹配网络范围\nNETMASK&#x3D;&quot;255.255.255.0&quot;\t\t# 子网掩码，固定写法255.255.255.0\nGATEWAY&#x3D;&quot;192.168.88.2&quot;\t\t# 网关，要和VMware中配置的一致\nDNS1&#x3D;&quot;192.168.88.2&quot;\t\t\t# DNS1服务器，和网关一致即可\n\nps命令功能：查看进程信息\n语法：ps -ef，查看全部进程信息，可以搭配grep做过滤：ps -ef | grep xxx\nkill命令\nnmap命令\nnetstat命令功能：查看端口占用\n用法：netstat -anp | grep xxx\nping命令测试网络是否联通\n语法：ping [-c num] 参数\n\nwget命令\ncurl命令\n\ntop命令功能：查看主机运行状态\n语法：top，查看基础信息\n可用选项：\n\n交互式模式中，可用快捷键：\n\ndf命令查看磁盘占用\n\niostat命令查看CPU、磁盘的相关信息\n\n\nsar命令查看网络统计\n\n环境变量\n临时设置：export 变量名&#x3D;变量值\n永久设置：\n针对用户，设置用户HOME目录内：.bashrc文件\n针对全局，设置/etc/profile\n\n\n\nPATH变量记录了执行程序的搜索路径\n可以将自定义路径加入PATH内，实现自定义命令在任意地方均可执行的效果\n$符号可以取出指定的环境变量的值\n语法：$变量名\n示例：\necho $PATH，输出PATH环境变量的值\necho $&#123;PATH&#125;ABC，输出PATH环境变量的值以及ABC\n如果变量名和其它内容混淆在一起，可以使用${}\n压缩解压压缩tar -zcvf 压缩包 被压缩1...被压缩2...被压缩N\n\n-z表示使用gzip，可以不写\n\nzip [-r] 参数1 参数2 参数N\n\n解压tar -zxvf 被解压的文件 -C 要解压去的地方\n\n-z表示使用gzip，可以省略\n-C，可以省略，指定要解压去的地方，不写解压到当前目录\n\nunzip [-d] 参数\n\nsu命令切换用户\n语法：su [-] [用户]\n\nsudo命令\n比如：\nitheima ALL&#x3D;(ALL)       NOPASSWD: ALL\n\n在visudo内配置如上内容，可以让itheima用户，无需密码直接使用sudo\nchmod命令修改文件、文件夹权限\n语法：chmod [-R] 权限 参数\n\n权限，要设置的权限，比如755，表示：rwxr-xr-x\n\n\n参数，被修改的文件、文件夹\n\n选项-R，设置文件夹和其内部全部内容一样生效\n\n\nchown命令修改文件、文件夹所属用户、组\n语法：chown [-R] [用户][:][用户组] 文件或文件夹\n\n用户组管理\n用户管理\ngenenv命令\ngetenv group，查看系统全部的用户组\n\n\ngetenv passwd，查看系统全部的用户\n\n\n\nenv命令查看系统全部的环境变量\n语法：env\n","slug":"Linux课程笔记","date":"2022-12-05T13:48:10.894Z","categories_index":"Linux","tags_index":"Linux课程笔记","author_index":"Areay7"},{"id":"596309cd0250881615133cb44c237a29","title":"Linux常用命令","content":" 一、vim常用：\n命令模式：dd    -&gt;   删除光标所在行\n命令模式：ndd    -&gt;   n为数字，删除当前光标向下n行\n命令模式：yy    -&gt;    复制当前行\n命令模式：nyy    -&gt;   n为数字，复制当前和下面n行\n命令模式：p    -&gt;   粘贴复制的内容\n命令模式：u    -&gt;   \t撤销修改\n命令模式：crtl + r     -&gt;   反向撤销修改\n命令模式：gg    -&gt;   光标跳到首行\n命令模式：G    -&gt;   光标跳到尾行\n命令模式：dG    -&gt;   从当前行开始，向下全部删除\n命令模式：dGG    -&gt;   从当前行开始，向上全部删除\n命令模式：d$\t    -&gt;   从当前光标开始，删除到本行末尾\n底线命令模式：  :wq    -&gt;    保存并退出\n底线命令模式：  :q    -&gt;    仅退出\n底线命令模式：  :q!    -&gt;    强制退出\n底线命令模式：  :w    -&gt;    仅保存\n底线命令模式：  :set nu    -&gt;    显示行号\n底线命令模式：  :set paste    -&gt;    设置粘贴模式(用于粘贴其他地方复制的东西)\n二、Linux用户权限\n（以下需要使用root用户执行）\n创建用户:\nuseradd [-g -d] 用户名\n（-g指定用户的组-d指定用户HOME路径,不指定HOME目录默认在: &#x2F;home&#x2F;用户名）\n 删除用户：\nuserdel [-r] 用户名\n(-r删除用户的HOME目录，不使用-r，HOME目标保留)\n查看用户所属组：\nid [用户名]\n（参数用户用于被查看的用户，不提供则查看自身）\n修改用户所属组：\nUsername -aG 用户组 用户名 \n（将用户加入指定用户组）\n（以下命令不需要root用户权限）\ngetent passwd  -&gt; 查看当前系统有哪些用户\ngetent group  -&gt; 查看当前系统有哪些用户组\ngroupadd  -&gt; 添加组\ngroupdel  -&gt; 删除组\nLinux可以支持 多用户、多用户组、用户加入多个组\nLinux权限管控的单元是用户级别和用户组级别\n权限细节：ls-l  (总共分为10个槽位)\n第1卡槽： -或d或l ，  -：文件  d：文件夹  l：软连接\n第2-4卡槽：  wxr  （所属用户权限）\n第5-7卡槽： wxr  （所属用户组权限）\n第8-10卡槽： wxr （所属其他用户权限）\n修改文件、文件夹权限信息：(只有文件所属用户或root用户有权修改) \n（-R对文件夹内全部内容应用同样操作）\n命令： chmod [-R]  权限 文件夹(文件)    \n(u：表示用户权限， g：表示组权限， o：表示其他用户权限 )\n示例： chmod u&#x3D;wxr,g&#x3D;wxr,o&#x3D;x test.txt\n权限的数字序号：(第一位表示用户权限，第二位表示所属组权限，第三位其他用户权限)   r记为4， w记为2， x记为1 , 0 表示无任何权限  (自行组合)\n常用  777（rwx,rwx,rwx）  或  751(rxw,r-x,–x) ；\n示例： chmod 751 test.txt\n修改文件、文件夹所属用户和用户组(只适于root用户)\nchown [-R]  用户:用户组  文件或文件夹\n示例： chown [-R] root:root test.txt\n三、常用操作(快捷键)\n强制停止  -&gt;   crtl + c\n退出登陆(包括python等)  -&gt;  crtl + d\n查看历史命令  -&gt;   history\n(history后使用)通过前缀自动执行上次匹配前缀的命令  -&gt;   !py\n(history后使用)输入内容区匹配历史命令  -&gt;   crtl + r        然后输入需要匹配的内容\n光标快速跳到命令开头    -&gt;     crtl + a\n光标快速跳到命令结尾    -&gt;     crtl + e\n光标快速跳左移一个单词    -&gt;     crtl + 方向左键\n光标快速跳右移一个单词    -&gt;     crtl + 方向右键\n清屏  -&gt;   crtl +  l    或  clear\n四、软件安装(Centos使用yum管理器，Ubuntu使用apt管理器)\nCentos：     yum -y [install] | [remove] | [search]  软件名称       (需要root权限、联网）\n-y 自动确认    install 安装   remove 移除   search 搜索      （包的格式为npm）\n示例：  yum -y install wget\nUbuntu：  apt -y [install] | [remove] | [search]  软件名称   (需要root权限、联网）\n-y 自动确认    install 安装   remove 移除   search 搜索      （包的格式为deb）\n示例：  apt -y install wget\n五、 systemctl 命令的使用:\n语法： systemctl status | start | stop | enable | disable  服务名\nstart(启动)  stop(关闭)  status(状态)  enable(开机自启)  disable(关闭开机自启)\n内置服务举例:  NetworkManage (主网络服务)  network(副网络服务)  firewalld(防火墙服务)  sshd，ssh服务(Linux远程登录常用,默认端口为22)\n示例： systemctl enable sshd\n六、 ln命令创建软连接(类似Windos中的快捷方式):\n语法： ln  -s   参数1   参数2\n-s 选项 ：  创建软连接\n参数1:   被链接的文件或文件夹\n参数2:   要链接去的目的地\n示例：  ln -s  &#x2F;etc&#x2F;yum.conf  ~&#x2F;yum.conf\n七、 date命令详解：\n语法：  date    [-d]    +格式化字符\ndate   -&gt;   直接查看时间\ndate  +%Y-%m-%d   -&gt;   按照 2022-01-01显示时间\ndate   “+%Y-%m-%d  %H:%M:%S”  -&gt;   按照 2022-01-01 10:00:00 显示时间(中间带括号，需要使用双引号包围所格式化字符串)\nntp  -u  ntp.aliyun.com  -&gt;  自动校准时间(需要root权限，需要安装ntp,也可以用systemctl设置开机自启)\n八、  静态ip配置及主机名相关操作: \nifconfig  -&gt;  查看本机ip (如无法使用，可安装 net-tools )  \nhostname  -&gt;   查看主机名  \nhostnamectl  set-hostname  主机名  修改主机名    -&gt;    修改主机名(需root权限)\nWindos下:    C:\\Windos\\System32\\drivers\\etc\\hosts   -&gt;     私人地址本\nLinux下:    &#x2F;etc&#x2F;hosts   -&gt;   私人地址本\n在  &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33 文件中  -&gt;  配置静态ip\nBOOTPROTO  -&gt;   由 dhcp 改为  static\nONBOOT  -&gt;  由 no  改为  yes\n新增如下内容(示例)：\nIPADDR&#x3D;”192.168.88.130”     \nNETMASK&#x3D;”255.255.255.0”\nGATEWAY&#x3D;”192.168.88.2”\nDNS1&#x3D;”192.168.88.2”\n在VMware Fusion中配置固定IP\n先备份文件:  cp &#x2F;Library&#x2F;Preferences&#x2F;VMware\\ Fusion&#x2F;vmnet8&#x2F;nat.conf &#x2F;Library&#x2F;Preferences&#x2F;VMware\\ Fusion&#x2F;vmnet8&#x2F;nat.conf.backup\n然后修改文件:  vim &#x2F;Library&#x2F;Preferences&#x2F;VMware\\ Fusion&#x2F;vmnet8&#x2F;nat.conf\n在 # NAT gateway address 配置(示例)：\nip &#x3D; 192.168.88.2netmask&#x3D;255.255.255.0\n","slug":"Linux常用命令","date":"2022-12-05T13:48:10.892Z","categories_index":"Linux","tags_index":"Linux常用命令","author_index":"Areay7"},{"id":"58a538c8f9e0979adba48f5c41a99c95","title":"Linux系统软件安装","content":"实战章节：在Linux上部署各类软件前言为什么学习各类软件在Linux上的部署在前面，我们学习了许多的Linux命令和高级技巧，这些知识点比较零散，同学们跟随着课程的内容进行练习虽然可以基础掌握这些命令和技巧的使用，但是并没有一些具体的实操能够串联起来这些知识点。\n所以，现在我们设计了各类软件在Linux上部署安装的实战章节，可以让同学们：\n\n对前面学习的各类操作命令进行复习和练习，从而深度掌握它们\n本章节中演示部署的软件，包含了IT行业各类岗位中所必须使用的，如：Java后台、大数据开发、运维开发、测试、AI等。无论学习Linux后从事什么岗位，这些内容都会给你带来帮助\n\n\n\n\n\n\n\n\n\n\n对于零基础学员，实战课程中所讲解的软件大概率多数大家并不了解。\n所以，课程仅涉及到安装部署，不对软件的使用做详细说明。\n同学们在这个过程中，可能会遇到各种各样的错误，不要怕，解决它，将会给你带来极大的提升。\n学习目标对于本部分的内容学习，我们设计两个目标：\n\n对于零基础或未从业的学员，不要求深入理解所安装部署的软件是什么，仅仅能够跟随课程成功的将其部署安装并运行成功即可\n在这个过程中，主要锻炼大家对Linux操作系统的熟练度，此乃零基础未从业学员的第一学习目标\n\n对于有基础或已从业的学员，本章节讲解的软件涵盖了大多数IT从业者所能接触到的，特别是大数据开发、后端开发两个主流方向，可以作为参考资料，以便在工作中有所帮助。\n\n\n本章节内的各类软件安装，&#x3D;&#x3D;不强制要求全部学习&#x3D;&#x3D;\n\n零基础学员，建议全部学习，作为前面学习内容的总结和实战\nIT从业者、有经验学员，可以按需选择，选择工作中需要用到的进行学习\n\n\n\n\n\n\n\n\n\n\n章节内包含的软件并非100%涵盖了IT开发领域中所需要的内容。\n如果您对某些软件的安装有强烈需求，且课程中没有提供教程，可以私信B站：”黑马大数据曹老师”，老师会酌情根据时间安排补充上去哦。\n为什么不使用PPT而是使用文档进行授课从现在开始，将要进入到Linux的实操阶段，在这个阶段我们将会涉及到非常多的软件部署等操作，涉及到：\n\n各类命令的使用\n各种过程的结果\n复杂的流程步骤\n等\n\n这些信息的展示，并不适合于使用PPT作为载体进行授课，所以从现在开始我们将使用操作文档的模式为大家进行讲解。\n\n\n\n\n\n\n\n\n\n使用文档模式还有一个好处，除了学习视频以外，拿到课程中使用的操作文档，同样可以作为重要的参考手册进行使用。\n一举两得\n前置要求\n实战章节要求同学们&#x3D;&#x3D;务必全部学习前面的知识点&#x3D;&#x3D;，即：初识Linux、Linux基础命令、Linux权限管理、Linux高阶技巧这4个章节，请勿跳过前面的章节学习实战章节。\n实战章节中会开启多台虚拟机，请尽量确保电脑的内存在：8GB（包含8GB）以上。如内存不足可以扩充内存条或购买阿里云、UCloud等云服务器临时使用（1个月多台低配服务器几十块左右）\n\n\n\n\n\n\n\n\n\n\n对于云平台上购买服务器，可以参阅最后的章节（云服务）\n注意下面全部的软件安装的相关流程，90%都是取自软件自身的官方网站。\n一个合格的程序员要有良好的信息收集能力哦\nMySQL数据库管理系统安装部署【简单】简介MySQL数据库管理系统（后续简称MySQL），是一款知名的数据库系统，其特点是：轻量、简单、功能丰富。\nMySQL数据库可谓是软件行业的明星产品，无论是后端开发、大数据、AI、运维、测试等各类岗位，基本上都会和MySQL打交道。\n让我们从MySQL开始，进行实战的Linux软件安装部署。\n本次课程分为2个版本进行安装：\n\nMySQL 5.7版本安装\nMySQL 8.x版本安装\n\n\n\n\n\n\n\n\n\n\n由于MySQL5.x和8.x各自有许多使用者，所以这两个版本我们都演示安装一遍\n注意MySQL的安装过程中，除了会使用Linux命令外，还会使用到少量的数据库专用的：SQL语句\n对于SQL语句我们并未涉及，所以可以跟随教程的内容，复制粘贴即可\n如对MySQL感兴趣，可以学习BiliBili黑马程序员视频：2022新版黑马程序员MySQL知识精讲+mysql实战案例_零基础mysql数据库入门到高级全套教程\n\n\n\n\n\n\n\n\n\n如有时间，建议可以在学习完Linux系统之后，学习一下MySQL数据库\n无论从事什么方面的开发，Java后端、大数据、AI、前端、Linux运维等，都会要求掌握MySQL数据库的\n可以说，MySQL是IT开发从业者必备的技能了。\nMySQL5.7版本在CentOS系统安装\n\n\n\n\n\n\n\n\n注意：安装操作需要root权限\nMySQL的安装我们可以通过前面学习的yum命令进行。\n安装\n配置yum仓库\n# 更新密钥\nrpm --import https:&#x2F;&#x2F;repo.mysql.com&#x2F;RPM-GPG-KEY-mysql-2022\n\n# 安装Mysql yum库\nrpm -Uvh http:&#x2F;&#x2F;repo.mysql.com&#x2F;&#x2F;mysql57-community-release-el7-7.noarch.rpm\n\n\n\n\n\n\n\n\n\n\n\n由于MySQL并不在CentOS的官方仓库中，所以我们通过上述rpm命令：\n\n导入MySQL仓库的密钥\n配置MySQLQ的yum仓库\n\n\n使用yum安装MySQL\n# yum安装Mysql\nyum -y install mysql-community-server\n\n\n\n安装完成后，启动MySQL并配置开机自启动\nsystemctl start mysqld\t\t# 启动\nsystemctl enable mysqld\t\t# 开机自启\n\n\n\n\n\n\n\n\n\n\nMySQL安装完成后，会自动配置为名称叫做：mysqld的服务，可以被systemctl所管理\n\n检查MySQL的运行状态\nsystemctl status mysqld\n\n\n\n\n配置主要配置管理员用户root的密码以及配置允许远程登录的权限。\n\n获取MySQL的初始密码\n# 通过grep命令，在&#x2F;var&#x2F;log&#x2F;mysqld.log文件中，过滤temporary password关键字，得到初始密码\ngrep &#39;temporary password&#39; &#x2F;var&#x2F;log&#x2F;mysqld.log\n\n\n\n登陆MySQL数据库系统\n# 执行\nmysql -uroot -p\n# 解释\n# -u，登陆的用户，MySQL数据库的管理员用户同Linux一样，是root\n# -p，表示使用密码登陆\n\n# 执行完毕后输入刚刚得到的初始密码，即可进入MySQL数据库\n\n\n\n修改root用户密码\n# 在MySQL控制台内执行\nALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;密码&#39;;\t-- 密码需要符合：大于8位，有大写字母，有特殊符号，不能是连续的简单语句如123，abc\n\n[扩展]，配置root的简单密码\n\n\n\n\n\n\n\n\n\n我们可以给root设置简单密码，如123456.\n请注意，此配置仅仅是用于测试环境或学习环境的MySQL，如果是正式使用，请勿设置简单密码\n# 如果你想设置简单密码，需要降低Mysql的密码安全级别\nset global validate_password_policy&#x3D;LOW; # 密码安全级别低\nset global validate_password_length&#x3D;4;\t # 密码长度最低4位即可\n\n# 然后就可以用简单密码了（课程中使用简单密码，为了方便，生产中不要这样）\nALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;简单密码&#39;;\n\n[扩展]，配置root运行远程登录\n\n\n\n\n\n\n\n\n\n默认情况下，root用户是不运行远程登录的，只允许在MySQL所在的Linux服务器登陆MySQL系统\n请注意，允许root远程登录会带来安全风险\n# 授权root远程登录\ngrant all privileges on *.* to root@&quot;IP地址&quot; identified by &#39;密码&#39; with grant option;  \n# IP地址即允许登陆的IP地址，也可以填写%，表示允许任何地址\n# 密码表示给远程登录独立设置密码，和本地登陆的密码可以不同\n\n# 刷新权限，生效\nflush privileges;\n\n退出MySQL控制台页面\n# 退出命令\nexit\n\n# 或者通过快捷键退出：ctrl + d\n\n检查端口\nMySQL默认绑定了3306端口，可以通过端口占用检查MySQL的网络状态\nnetstat -anp | grep 3306\n\n\n\n\n至此，MySQL就安装完成并可用了，请妥善保存好MySQL的root密码。\nMySQL8.0版本在CentOS系统安装\n\n\n\n\n\n\n\n\n注意：安装操作需要root权限\n安装\n配置yum仓库\n# 更新密钥\nrpm --import https:&#x2F;&#x2F;repo.mysql.com&#x2F;RPM-GPG-KEY-mysql-2022\n\n# 安装Mysql8.x版本 yum库\nrpm -Uvh https:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;mysql80-community-release-el7-2.noarch.rpm\n\n使用yum安装MySQL\n# yum安装Mysql\nyum -y install mysql-community-server\n\n安装完成后，启动MySQL并配置开机自启动\nsystemctl start mysqld\t\t# 启动\nsystemctl enable mysqld\t\t# 开机自启\n\n\n\n\n\n\n\n\n\n\nMySQL安装完成后，会自动配置为名称叫做：mysqld的服务，可以被systemctl所管理\n\n检查MySQL的运行状态\nsystemctl status mysqld\n\n配置主要修改root密码和允许root远程登录\n\n获取MySQL的初始密码\n# 通过grep命令，在&#x2F;var&#x2F;log&#x2F;mysqld.log文件中，过滤temporary password关键字，得到初始密码\ngrep &#39;temporary password&#39; &#x2F;var&#x2F;log&#x2F;mysqld.log\n\n登录MySQL数据库系统\n# 执行\nmysql -uroot -p\n# 解释\n# -u，登陆的用户，MySQL数据库的管理员用户同Linux一样，是root\n# -p，表示使用密码登陆\n\n# 执行完毕后输入刚刚得到的初始密码，即可进入MySQL数据库\n\n修改root密码\nALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED WITH mysql_native_password BY &#39;密码&#39;;\t-- 密码需要符合：大于8位，有大写字母，有特殊符号，不能是连续的简单语句如123，abc\n\n[扩展]，配置root的简单密码\n\n\n\n\n\n\n\n\n\n我们可以给root设置简单密码，如123456.\n请注意，此配置仅仅是用于测试环境或学习环境的MySQL，如果是正式使用，请勿设置简单密码\nset global validate_password.policy&#x3D;0;\t\t# 密码安全级别低\nset global validate_password.length&#x3D;4;\t\t# 密码长度最低4位即可\n\n\n\n允许root远程登录，并设置远程登录密码\n\n\n\n\n\n\n\n\n\n默认情况下，root用户是不运行远程登录的，只允许在MySQL所在的Linux服务器登陆MySQL系统\n请注意，允许root远程登录会带来安全风险\n# 第一次设置root远程登录，并配置远程密码使用如下SQL命令\ncreate user &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;密码!&#39;;\t-- 密码需要符合：大于8位，有大写字母，有特殊符号，不能是连续的简单语句如123，abc\n\n# 后续修改密码使用如下SQL命令\nALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;密码&#39;;\n\n退出MySQL控制台页面\n# 退出命令\nexit\n\n# 或者通过快捷键退出：ctrl + d\n\n检查端口\nMySQL默认绑定了3306端口，可以通过端口占用检查MySQL的网络状态\nnetstat -anp | grep 3306\n\n\n\n\n至此，MySQL就安装完成并可用了，请妥善保存好MySQL的root密码。\nMySQL5.7版本在Ubuntu（WSL环境）系统安装\n\n\n\n\n\n\n\n\n课程中配置的WSL环境是最新的Ubuntu22.04版本，这个版本的软件商店内置的MySQL是8.0版本\n所以我们需要额外的步骤才可以安装5.7版本的MySQL\n安装操作需root权限，你可以：\n\n通过 sudo su -，切换到root用户\n\n\n\n\n\n\n\n\n\n课程中选择这种方式操作\n\n或在每一个命令前，加上sudo，用来临时提升权限\n\n\n安装\n下载apt仓库文件\n# 下载apt仓库的安装包，Ubuntu的安装包是.deb文件\nwget https:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;mysql-apt-config_0.8.12-1_all.deb\n\n\n\n配置apt仓库\n# 使用dpkg命令安装仓库\ndpkg -i mysql-apt-config_0.8.12-1_all.deb\n\n弹出框中选择：ubuntu bionic （Ubuntu18.04系统的代号是bionic，选择18.04的版本库用来安装）\n\n弹出框中选择：MySQL Server &amp; Cluster\n\n弹出框中选择：mysql-5.7\n\n最后选择：ok\n\n\n更新apt仓库的信息\n# 首先导入仓库的密钥信息\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys 467B942D3A79BD29\n# 更新仓库信息\napt update\n\n检查是否成功配置MySQL5.7的仓库\napt-cache policy mysql-server\n\n\n看到如图所示字样，即成功\n\n安装MySQL5.7\n# 使用apt安装mysql客户端和mysql服务端\napt install -f -y mysql-client&#x3D;5.7* mysql-community-server&#x3D;5.7*\n\n弹出框中输入root密码并选择ok，密码任意，课程中以123456代替\n\n再次输入root密码确认\n\n\n启动MySQL\n&#x2F;etc&#x2F;init.d&#x2F;mysql start\t\t\t# 启动\n&#x2F;etc&#x2F;init.d&#x2F;mysql stop\t\t\t# 停止\n&#x2F;etc&#x2F;init.d&#x2F;mysql status\t\t# 查看状态\n\n\n\n对MySQL进行初始化\n# 执行如下命令，此命令是MySQL安装后自带的配置程序\nmysql_secure_installation\n# 可以通过which命令查看到这个自带程序所在的位置\nroot@DESKTOP-Q89USRE:~# which mysql_secure_installation\n&#x2F;usr&#x2F;bin&#x2F;mysql_secure_installation\n\n\n输入密码：\n\n\n是否开启密码验证插件，如果需要增强密码安全性，输入y并回车，不需要直接回车（课程中选择直接回车）\n\n\n是否更改root密码，需要输入y回车，不需要直接回车（课程不更改）\n\n\n是否移除匿名用户，移除输入y回车，不移除直接回车（课程选择移除）\n\n\n是否进制root用户远程登录，禁止输入y回车，不禁止直接回车（课程选择不禁止）\n\n\n是否移除自带的测试数据库，移除输入y回车，不移除直接回车（课程选择不移除）\n\n\n是否刷新权限，刷新输入y回车，不刷新直接回车（课程选择刷新）\n\n\n\n\n登陆MySQL\nmysql -uroot -p\n# 输入密码即可登陆成功\n\n\n\n\n至此，在Ubuntu上安装MySQL5.7版本成功。\nMySQL8.0版本在Ubuntu（WSL环境）系统安装\n\n\n\n\n\n\n\n\n课程中配置的WSL环境是最新的Ubuntu22.04版本，这个版本的软件商店内置的MySQL是8.0版本\n所以直接可以通过apt安装即可\n\n\n\n\n\n\n\n\n\n注意，课程是以WSL获得的Ubuntu操作系统环境。\n如果你通过VMware虚拟机的方式获得了Ubuntu操作系统环境，操作步骤不用担心，和课程中使用WSL环境是&#x3D;&#x3D;完全一致的&#x3D;&#x3D;\n安装操作需root权限，你可以：\n\n通过 sudo su -，切换到root用户\n\n\n\n\n\n\n\n\n\n课程中选择这种方式操作\n\n或在每一个命令前，加上sudo，用来临时提升权限\n\n\n安装\n如果已经安装过MySQL5.7版本，需要卸载仓库信息哦\n# 卸载MySQL5.7版本\napt remove -y mysql-client&#x3D;5.7* mysql-community-server&#x3D;5.7*\n\n# 卸载5.7的仓库信息\ndpkg -l | grep mysql | awk &#39;&#123;print $2&#125;&#39; | xargs dpkg -P\n\n更新apt仓库信息\napt update\n\n安装mysql\napt install -y mysql-server\n\n启动MySQL\n&#x2F;etc&#x2F;init.d&#x2F;mysql start\t\t\t# 启动\n&#x2F;etc&#x2F;init.d&#x2F;mysql stop\t\t\t# 停止\n&#x2F;etc&#x2F;init.d&#x2F;mysql status\t\t# 查看状态\n\n登陆MySQL设置密码\n# 直接执行：mysql\nmysql\n\n设置密码\nALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED WITH mysql_native_password BY &#39;password&#39;;\n\n退出MySQL控制台\nexit\n\n对MySQL进行初始化\n# 执行如下命令，此命令是MySQL安装后自带的配置程序\nmysql_secure_installation\n# 可以通过which命令查看到这个自带程序所在的位置\nroot@DESKTOP-Q89USRE:~# which mysql_secure_installation\n&#x2F;usr&#x2F;bin&#x2F;mysql_secure_installation\n\n\n输入密码：\n\n\n是否开启密码验证插件，如果需要增强密码安全性，输入y并回车，不需要直接回车（课程中选择直接回车）\n\n\n是否更改root密码，需要输入y回车，不需要直接回车（课程不更改）\n\n\n是否移除匿名用户，移除输入y回车，不移除直接回车（课程选择移除）\n\n\n是否进制root用户远程登录，禁止输入y回车，不禁止直接回车（课程选择不禁止）\n\n\n是否移除自带的测试数据库，移除输入y回车，不移除直接回车（课程选择不移除）\n\n\n是否刷新权限，刷新输入y回车，不刷新直接回车（课程选择刷新）\n\n\n\n\n重新登陆MySQL（用更改后的密码）\nmysql -uroot -p\n\n\n\n\n至此，在Ubuntu上安装MySQL5.7版本成功。\nTomcat安装部署【简单】简介Tomcat 是由 Apache 开发的一个 Servlet 容器，实现了对 Servlet 和 JSP 的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。\n简单来说，Tomcat是一个WEB应用程序的托管平台，可以让用户编写的WEB应用程序，被Tomcat所托管，并提供网站服务。\n\n\n\n\n\n\n\n\n\n即让用户开发的WEB应用程序，变成可以被访问的网页。\n安装Tomcat的安装非常简单，主要分为2部分：\n\n安装JDK环境\n解压并安装Tomcat\n\n\n\n\n\n\n\n\n\n\n本次安装使用Tomcat版本是：10.0.27版本，需要Java（JDK）版本最低为JDK8或更高版本\n课程中使用的JDK版本是：JDK8u351版本\n安装JDK环境\n下载JDK软件\nhttps://www.oracle.com/java/technologies/downloads\n在页面下方找到：\n\n\n下载jdk-8u351-linux-x64.tar.gz\n\n&#x3D;&#x3D;在弹出的页面中输入Oracle的账户密码即可下载（如无账户，请自行注册，注册是免费的）&#x3D;&#x3D;\n\n登陆Linux系统，切换到root用户\n\n\n通过FinalShell，上传下载好的JDK安装包\n\n\n创建文件夹，用来部署JDK，将JDK和Tomcat都安装部署到：&#x2F;export&#x2F;server 内\nmkdir -p &#x2F;export&#x2F;server\n\n解压缩JDK安装文件\ntar -zxvf jdk-8u351-linux-x64.tar.gz -C &#x2F;export&#x2F;server\n\n配置JDK的软链接\nln -s &#x2F;export&#x2F;server&#x2F;jdk1.8.0_351 &#x2F;export&#x2F;server&#x2F;jdk\n\n配置JAVA_HOME环境变量，以及将$JAVA_HOME&#x2F;bin文件夹加入PATH环境变量中\n# 编辑&#x2F;etc&#x2F;profile文件\nexport JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk\nexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin\n\n生效环境变量\nsource &#x2F;etc&#x2F;profile\n\n配置java执行程序的软链接\n# 删除系统自带的java程序\nrm -f &#x2F;usr&#x2F;bin&#x2F;java\n# 软链接我们自己安装的java程序\nln -s &#x2F;export&#x2F;server&#x2F;jdk&#x2F;bin&#x2F;java &#x2F;usr&#x2F;bin&#x2F;java\n\n执行验证：\njava -version\njavac -version\n\n解压并部署Tomcat\n\n\n\n\n\n\n\n\nTomcat建议使用非Root用户安装并启动\n可以创建一个用户：tomcat用以部署\n\n首先，放行tomcat需要使用的8080端口的外部访问权限\n\n\n\n\n\n\n\n\n\nCentOS系统默认开启了防火墙，阻止外部网络流量访问系统内部\n所以，如果想要Tomcat可以正常使用，需要对Tomcat默认使用的8080端口进行放行\n放行有2种操作方式：\n\n关闭防火墙\n配置防火墙规则，放行端口\n\n# 以下操作2选一即可\n# 方式1：关闭防火墙\nsystemctl stop firewalld\t\t# 关闭防火墙\nsystemctl disable firewalld\t\t# 停止防火墙开机自启\n\n# 方式2：放行8080端口的外部访问\nfirewall-cmd --add-port&#x3D;8080&#x2F;tcp --permanent\t\t# --add-port&#x3D;8080&#x2F;tcp表示放行8080端口的tcp访问，--permanent表示永久生效\nfirewall-cmd --reload\t\t\t\t\t\t\t\t# 重新载入防火墙规则使其生效\n\n\n\n\n\n\n\n\n\n\n方便起见，建议同学们选择方式1，直接关闭防火墙一劳永逸\n防火墙的配置非常复杂，后面会视情况独立出一集防火墙配置规则的章节。\n\n以root用户操作，创建tomcat用户\n# 使用root用户操作\nuseradd tomcat\n# 可选，为tomcat用户配置密码\npasswd tomcat\n\n下载Tomcat安装包\n# 使用root用户操作\nwget https:&#x2F;&#x2F;dlcdn.apache.org&#x2F;tomcat&#x2F;tomcat-10&#x2F;v10.0.27&#x2F;bin&#x2F;apache-tomcat-10.0.27.tar.gz\n# 如果出现https相关错误，可以使用--no-check-certificate选项\nwget --no-check-certificate https:&#x2F;&#x2F;dlcdn.apache.org&#x2F;tomcat&#x2F;tomcat-10&#x2F;v10.0.27&#x2F;bin&#x2F;apache-tomcat-10.0.27.tar.gz\n\n\n\n\n\n\n\n\n\n\n如果Linux内下载过慢，可以复制下载链接在Windows系统中使用迅雷等软件加速下载然后上传到Linux内即可\n或者使用课程资料中提供的安装包\n\n解压Tomcat安装包\n# 使用root用户操作，否则无权限解压到&#x2F;export&#x2F;server内，除非修改此文件夹权限\ntar -zxvf apache-tomcat-10.0.27.tar.gz -C &#x2F;export&#x2F;server\n\n创建Tomcat软链接\n# 使用root用户操作\nln -s &#x2F;export&#x2F;server&#x2F;apache-tomcat-10.0.27 &#x2F;export&#x2F;server&#x2F;tomcat\n\n修改tomcat安装目录权限\n# 使用root用户操作，同时对软链接和tomcat安装文件夹进行修改，使用通配符*进行匹配\nchown -R tomcat:tomcat &#x2F;export&#x2F;server&#x2F;*tomcat*\n\n切换到tomcat用户\nsu - tomcat\n\n启动tomcat\n&#x2F;export&#x2F;server&#x2F;tomcat&#x2F;bin&#x2F;startup.sh\n\ntomcat启动在8080端口，可以检查是否正常启动成功\nnetstat -anp | grep 8080\n\n\n\n打开浏览器，输入：\nhttp://centos:8080或http://192.168.88.130:8080\n使用主机名（需配置好本地的主机名映射）或IP地址访问Tomcat的WEB页面\n\n\n\n至此，Tomcat安装配置完成。\nNginx安装部署【简单】简介Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP&#x2F;POP3&#x2F;SMTP服务。\n同Tomcat一样，Nginx可以托管用户编写的WEB应用程序成为可访问的网页服务，同时也可以作为流量代理服务器，控制流量的中转。\nNginx在WEB开发领域，基本上也是必备组件之一了。\n安装Nginx同样需要配置额外的yum仓库，才可以使用yum安装\n\n\n\n\n\n\n\n\n\n安装Nginx的操作需要root身份\n\n安装yum依赖程序\n# root执行\nyum install -y yum-utils\n\n手动添加，nginx的yum仓库\nyum程序使用的仓库配置文件，存放在：/etc/yum.repo.d内。\n# root执行\n# 创建文件使用vim编辑\nvim &#x2F;etc&#x2F;yum.repos.d&#x2F;nginx.repo\n# 填入如下内容并保存退出\n[nginx-stable]\nname&#x3D;nginx stable repo\nbaseurl&#x3D;http:&#x2F;&#x2F;nginx.org&#x2F;packages&#x2F;centos&#x2F;$releasever&#x2F;$basearch&#x2F;\ngpgcheck&#x3D;1\nenabled&#x3D;1\ngpgkey&#x3D;https:&#x2F;&#x2F;nginx.org&#x2F;keys&#x2F;nginx_signing.key\nmodule_hotfixes&#x3D;true\n\n[nginx-mainline]\nname&#x3D;nginx mainline repo\nbaseurl&#x3D;http:&#x2F;&#x2F;nginx.org&#x2F;packages&#x2F;mainline&#x2F;centos&#x2F;$releasever&#x2F;$basearch&#x2F;\ngpgcheck&#x3D;1\nenabled&#x3D;0\ngpgkey&#x3D;https:&#x2F;&#x2F;nginx.org&#x2F;keys&#x2F;nginx_signing.key\nmodule_hotfixes&#x3D;true\n\n\n\n\n\n\n\n\n\n\n通过如上操作，我们手动添加了nginx的yum仓库\n\n通过yum安装最新稳定版的nginx\n# root执行\nyum install -y nginx\n\n启动\n# nginx自动注册了systemctl系统服务\nsystemctl start nginx\t\t# 启动\nsystemctl stop nginx\t\t# 停止\nsystemctl status nginx\t\t# 运行状态\nsystemctl enable nginx\t\t# 开机自启\nsystemctl disable nginx\t\t# 关闭开机自启\n\n配置防火墙放行\nnginx默认绑定80端口，需要关闭防火墙或放行80端口\n# 方式1（推荐），关闭防火墙\nsystemctl stop firewalld\t\t# 关闭\nsystemctl disable firewalld\t\t# 关闭开机自启\n\n# 方式2，放行80端口\nfirewall-cmd --add-port&#x3D;80&#x2F;tcp --permanent\t\t# 放行tcp规则下的80端口，永久生效\nfirewall-cmd --reload\t\t\t\t\t\t\t# 重新加载防火墙规则\n\n启动后浏览器输入Linux服务器的IP地址或主机名即可访问\nhttp://192.168.88.130 或 http://centos\n\n\n\n\n\n\n\n\n\nps：80端口是访问网站的默认端口，所以后面无需跟随端口号\n显示的指定端口也是可以的比如：\n\nhttp://192.168.88.130:80\nhttp://centos:80\n\n\n\n至此，Nginx安装配置完成。\n\nRabbitMQ安装部署【简单】简介RabbitMQ一款知名的开源消息队列系统，为企业提供消息的发布、订阅、点对点传输等消息服务。\nRabbitMQ在企业开发中十分常见，课程为大家演示快速搭建RabbitMQ环境。\n安装\n\n\n\n\n\n\n\n\nrabbitmq在yum仓库中的版本比较老，所以我们需要手动构建yum仓库\n\n准备yum仓库\n# root执行\n# 1. 准备gpgkey密钥\nrpm --import https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;signing-keys&#x2F;releases&#x2F;download&#x2F;2.0&#x2F;rabbitmq-release-signing-key.asc\nrpm --import https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;erlang&#x2F;gpgkey\nrpm --import https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;gpgkey\n\n# 2. 准备仓库文件\nvim &#x2F;etc&#x2F;yum.repos.d&#x2F;rabbitmq.repo\n# 填入如下内容\n##\n## Zero dependency Erlang\n##\n\n[rabbitmq_erlang]\nname&#x3D;rabbitmq_erlang\nbaseurl&#x3D;https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;erlang&#x2F;el&#x2F;7&#x2F;$basearch\nrepo_gpgcheck&#x3D;1\ngpgcheck&#x3D;1\nenabled&#x3D;1\n# PackageCloud&#39;s repository key and RabbitMQ package signing key\ngpgkey&#x3D;https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;erlang&#x2F;gpgkey\n       https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;signing-keys&#x2F;releases&#x2F;download&#x2F;2.0&#x2F;rabbitmq-release-signing-key.asc\nsslverify&#x3D;1\nsslcacert&#x3D;&#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;ca-bundle.crt\nmetadata_expire&#x3D;300\n\n[rabbitmq_erlang-source]\nname&#x3D;rabbitmq_erlang-source\nbaseurl&#x3D;https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;erlang&#x2F;el&#x2F;7&#x2F;SRPMS\nrepo_gpgcheck&#x3D;1\ngpgcheck&#x3D;0\nenabled&#x3D;1\n# PackageCloud&#39;s repository key and RabbitMQ package signing key\ngpgkey&#x3D;https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;erlang&#x2F;gpgkey\n       https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;signing-keys&#x2F;releases&#x2F;download&#x2F;2.0&#x2F;rabbitmq-release-signing-key.asc\nsslverify&#x3D;1\nsslcacert&#x3D;&#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;ca-bundle.crt\nmetadata_expire&#x3D;300\n\n##\n## RabbitMQ server\n##\n\n[rabbitmq_server]\nname&#x3D;rabbitmq_server\nbaseurl&#x3D;https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;el&#x2F;7&#x2F;$basearch\nrepo_gpgcheck&#x3D;1\ngpgcheck&#x3D;0\nenabled&#x3D;1\n# PackageCloud&#39;s repository key and RabbitMQ package signing key\ngpgkey&#x3D;https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;gpgkey\n       https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;signing-keys&#x2F;releases&#x2F;download&#x2F;2.0&#x2F;rabbitmq-release-signing-key.asc\nsslverify&#x3D;1\nsslcacert&#x3D;&#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;ca-bundle.crt\nmetadata_expire&#x3D;300\n\n[rabbitmq_server-source]\nname&#x3D;rabbitmq_server-source\nbaseurl&#x3D;https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;el&#x2F;7&#x2F;SRPMS\nrepo_gpgcheck&#x3D;1\ngpgcheck&#x3D;0\nenabled&#x3D;1\ngpgkey&#x3D;https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;gpgkey\nsslverify&#x3D;1\nsslcacert&#x3D;&#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;ca-bundle.crt\nmetadata_expire&#x3D;300\n\n安装RabbitMQ\n# root执行\nyum install erlang rabbitmq-server -y\n\nInstalled:\n  erlang.x86_64 0:23.3.4.11-1.el7           rabbitmq-server.noarch 0:3.10.0-1.el7\n\n启动\n# root执行\n# 使用systemctl管控，服务名：rabbitmq-server\nsystemctl enable rabbitmq-server\t\t# 开机自启\nsystemctl disable rabbitmq-server\t\t# 关闭开机自启\nsystemctl start rabbitmq-server\t\t\t# 启动\nsystemctl stop rabbitmq-server\t\t\t# 关闭\nsystemctl status rabbitmq-server\t\t# 查看状态\n\n放行防火墙，RabbitMQ使用5672、15672、25672 3个端口\n# 方式1（推荐），关闭防火墙\nsystemctl stop firewalld\t\t# 关闭\nsystemctl disable firewalld\t\t# 关闭开机自启\n\n# 方式2，放行5672 25672端口\nfirewall-cmd --add-port&#x3D;5672&#x2F;tcp --permanent\t\t# 放行tcp规则下的5672端口，永久生效\nfirewall-cmd --add-port&#x3D;15672&#x2F;tcp --permanent\t\t# 放行tcp规则下的15672端口，永久生效\nfirewall-cmd --add-port&#x3D;25672&#x2F;tcp --permanent\t\t# 放行tcp规则下的25672端口，永久生效\nfirewall-cmd --reload\t\t\t\t\t\t\t\t# 重新加载防火墙规则\n\n启动RabbitMQ的WEB管理控制台\nrabbitmq-plugins enable rabbitmq_management\n\n添加admin用户，并赋予权限\nrabbitmqctl add_user admin &#39;Itheima66^&#39;\nrabbitmqctl set_permissions -p &quot;&#x2F;&quot; &quot;admin&quot; &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;\nrabbitmqctl set_user_tags admin administrator\n\n\n\n浏览器打开管理控制台\nhttp://192.168.88.130:15672\n\n\n\n至此，RabbitMQ已经安装完成了。\nRedis安装部署【简单】简介redis是一个开源的、使用C语言编写的、支持网络交互的、可基于内存也可持久化的Key-Value数据库。\nredis的特点就是：快，可以基于内存存储数据并提供超低延迟、超快的检索速度\n一般用于在系统中提供快速缓存的能力。\n安装\n配置EPEL仓库\n\n\n\n\n\n\n\n\n\nEPEL 的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。EPEL则为服务器版本提供大量的rpm包(yum程序所使用的程序安装包，类似Windows的exe)，而且大多数rpm包在官方 repository 中是找不到的。\n# root执行\nyum install -y epel-release\n\n安装redis\n# root执行\nyum install -y redis\n\n启动redis\n# root执行\n# 使用systemctl管控，服务名：redis\nsystemctl enable redis\t\t# 开机自启\nsystemctl disable redis\t\t# 关闭开机自启\nsystemctl start redis\t\t# 启动\nsystemctl stop redis\t\t# 关闭\nsystemctl status redis\t\t# 查看状态\n\n放行防火墙，redis使用端口6379\n# 方式1（推荐），关闭防火墙\nsystemctl stop firewalld\t\t# 关闭\nsystemctl disable firewalld\t\t# 关闭开机自启\n\n# 方式2，放行6379端口\nfirewall-cmd --add-port&#x3D;6379&#x2F;tcp --permanent\t\t# 放行tcp规则下的6379端口，永久生效\nfirewall-cmd --reload\t\n\n进入redis服务\n# 执行redis-cli\n[root@centos ~]# redis-cli\n127.0.0.1:6379&gt; set mykey hello\nOK\n127.0.0.1:6379&gt; get mykey\n&quot;hello&quot;\n127.0.0.1:6379&gt; \n\n至此，redis安装完成。\nElasticSearch安装部署简介全文搜索属于最常见的需求，开源的 Elasticsearch （以下简称 es）是目前全文搜索引擎的首选。\n它可以快速地储存、搜索和分析海量数据。维基百科、Stack Overflow、Github 都采用它。\nElasticsearch简称es，在企业内同样是一款应用非常广泛的搜索引擎服务。\n很多服务中的搜索功能，都是基于es来实现的。\n安装\n添加yum仓库\n# root执行\n# 导入仓库密钥\nrpm --import https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;GPG-KEY-elasticsearch\n\n# 添加yum源\n# 编辑文件 \nvim &#x2F;etc&#x2F;yum.repos.d&#x2F;elasticsearch.repo\n\n[elasticsearch-7.x]\nname&#x3D;Elasticsearch repository for 7.x packages\nbaseurl&#x3D;https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;packages&#x2F;7.x&#x2F;yum\ngpgcheck&#x3D;1\ngpgkey&#x3D;https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;GPG-KEY-elasticsearch\nenabled&#x3D;1\nautorefresh&#x3D;1\ntype&#x3D;rpm-md\n\n\n# 更新yum缓存\nyum makecache\n\n安装es\nyum install -y elasticsearch\n\n配置es\nvim &#x2F;etc&#x2F;elasticsearch&#x2F;elasticsearch.yml\n\n# 17行，设置集群名称\ncluster.name: my-cluster\n\n# 23行，设置节点名称\nnode.name: node-1\n\n# 56行，允许外网访问\nnetwork.host: 0.0.0.0\n\n# 74行，配置集群master节点\ncluster.initial_master_nodes: [&quot;node-1&quot;]\n\n启动es\nsystemctl start | stop | status | enable | disable elasticsearch\n\n关闭防火墙\nsystemctl stop firewalld\nsystemctl disable firewalld\n\n测试\n浏览器打开：http://ip:9200/?pretty\n\n\n\n集群化环境前置准备介绍在前面，我们所学习安装的软件，都是以单机模式运行的。\n后续，我们将要学习大数据相关的软件部署，所以后续我们所安装的软件服务，大多数都是以集群化（多台服务器共同工作）模式运行的。\n所以，在当前小节，我们需要完成集群化环境的前置准备，包括创建多台虚拟机，配置主机名映射，SSH免密登录等等。\n部署配置多台Linux虚拟机安装集群化软件，首要条件就是要有多台Linux服务器可用。\n我们可以使用VMware提供的克隆功能，将我们的虚拟机额外克隆出3台来使用。\n\n首先，关机当前CentOS系统虚拟机（可以使用root用户执行init 0来快速关机）\n\n新建文件夹\n\n文件夹起名为：虚拟机集群\n\n克隆\n\n\n\n\n\n\n\n\n\n同样的操作克隆出：node2和node3\n\n\n开启node1，修改主机名为node1，并修改固定ip为：192.168.88.131\n# 修改主机名\nhostnamectl set-hostname node1\n\n# 修改IP地址\nvim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33\nIPADDR&#x3D;&quot;192.168.88.131&quot;\n\n# 重启网卡\nsystemctl stop network\nsystemctl start network\n# 或者直接\nsystemctl restart network\n\n同样的操作启动node2和node3,\n修改node2主机名为node2，设置ip为192.168.88.132\n修改node2主机名为node3，设置ip为192.168.88.133\n\n配置FinalShell，配置连接到node1、node2、node3的连接\n\n\n\n\n\n\n\n\n\n为了简单起见，建议配置root用户登录\n\n\n准备主机名映射\n在Windows系统中修改hosts文件，填入如下内容：\n\n\n\n\n\n\n\n\n\n如果同学们使用MacOS系统，请：\n\nsudo su -，切换到root\n修改&#x2F;etc&#x2F;hosts文件\n\n192.168.88.131 node1\n192.168.88.132 node2\n192.168.88.133 node3\n\n在3台Linux的&#x2F;etc&#x2F;hosts文件中，填入如下内容（&#x3D;&#x3D;3台都要添加&#x3D;&#x3D;）\n192.168.88.131 node1\n192.168.88.132 node2\n192.168.88.133 node3\n\n配置SSH免密登录简介SSH服务是一种用于远程登录的安全认证协议。\n我们通过FinalShell远程连接到Linux，就是使用的SSH服务。\nSSH服务支持：\n\n通过账户+密码的认证方式来做用户认证\n通过账户+秘钥文件的方式做用户认证\n\nSSH可以让我们通过SSH命令，远程的登陆到其它的主机上，比如：\n在node1执行：ssh root@node2，将以root用户登录node2服务器，输入密码即可成功登陆\n或者ssh node2，将以当前用户直接登陆到node2服务器。\nSSH免密配置后续安装的集群化软件，多数需要远程登录以及远程执行命令，我们可以简单起见，配置三台Linux服务器之间的免密码互相SSH登陆\n\n在每一台机器都执行：ssh-keygen -t rsa -b 4096，一路回车到底即可\n\n在每一台机器都执行：\nssh-copy-id node1\nssh-copy-id node2\nssh-copy-id node3\n\n执行完毕后，node1、node2、node3之间将完成root用户之间的免密互通\n\n\n配置JDK环境后续的大数据集群软件，多数是需要Java运行环境的，所以我们为&#x3D;&#x3D;每一台&#x3D;&#x3D;机器都配置JDK环境。\nJDK配置参阅：Tomcat安装部署环节。\n关闭防火墙和SELinux集群化软件之间需要通过端口互相通讯，为了避免出现网络不通的问题，我们可以简单的在集群内部关闭防火墙。\n&#x3D;&#x3D;在每一台机器都执行&#x3D;&#x3D;\nsystemctl stop firewalld\nsystemctl disable firewalld\n\n\n\nLinux有一个安全模块：SELinux，用以限制用户和程序的相关权限，来确保系统的安全稳定。\nSELinux的配置同防火墙一样，非常复杂，课程中不多涉及，后续视情况可以出一章SELinux的配置课程。\n在当前，我们只需要关闭SELinux功能，避免导致后面的软件运行出现问题即可，\n&#x3D;&#x3D;在每一台机器都执行&#x3D;&#x3D;\nvim &#x2F;etc&#x2F;sysconfig&#x2F;selinux\n\n# 将第七行，SELINUX&#x3D;enforcing 改为\nSELINUX&#x3D;disabled\n# 保存退出后，重启虚拟机即可，千万要注意disabled单词不要写错，不然无法启动系统\n\n\n\n\n\n添加快照为了避免后续出现问题，在完成上述设置后，为&#x3D;&#x3D;每一台虚拟机&#x3D;&#x3D;都制作快照，留待使用。\n补充命令 - scp后续的安装部署操作，我们将会频繁的在多台服务器之间相互传输数据。\n为了更加方面的互相传输，我们补充一个命令：scp\nscp命令是cp命令的升级版，即：ssh cp，通过SSH协议完成文件的复制。\n其主要的功能就是：在不同的Linux服务器之间，通过SSH协议互相传输文件。\n只要知晓服务器的账户和密码（或密钥），即可通过SCP互传文件。\n语法：\nscp [-r] 参数1 参数2\n- -r选项用于复制文件夹使用，如果复制文件夹，必须使用-r\n- 参数1：本机路径 或 远程目标路径\n- 参数2：远程目标路径 或 本机路径\n\n如：\nscp -r &#x2F;export&#x2F;server&#x2F;jdk root@node2:&#x2F;export&#x2F;server&#x2F;\n将本机上的jdk文件夹， 以root的身份复制到node2的&#x2F;export&#x2F;server&#x2F;内\n同SSH登陆一样，账户名可以省略（使用本机当前的同名账户登陆）\n\n如：\nscp -r node2:&#x2F;export&#x2F;server&#x2F;jdk &#x2F;export&#x2F;server&#x2F;\n将远程node2的jdk文件夹，复制到本机的&#x2F;export&#x2F;server&#x2F;内\n\n\n# scp命令的高级用法\ncd &#x2F;export&#x2F;server\nscp -r jdk node2:&#96;pwd&#96;&#x2F;    # 将本机当前路径的jdk文件夹，复制到node2服务器的同名路径下\nscp -r jdk node2:$PWD      # 将本机当前路径的jdk文件夹，复制到node2服务器的同名路径下\n\n\n\n\n\n\n\n\n\n\n\nZookeeper集群安装部署简介ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n除了为Hadoop和HBase提供协调服务外，Zookeeper也被其它许多软件采用作为其分布式状态一致性的依赖，比如Kafka，又或者一些软件项目中，也经常能见到Zookeeper作为一致性协调服务存在。\nZookeeper不论是大数据领域亦或是其它服务器开发领域，涉及到分布式状态一致性的场景，总有它的身影存在。\n安装Zookeeper是一款分布式的集群化软件，可以在多台服务器上部署，并协同组成分布式集群一起工作。\n\n首先，要确保已经完成了集群化环境前置准备环节的全部内容\n\n【node1上操作】下载Zookeeper安装包，并解压\n# 下载\nwget http:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;zookeeper&#x2F;zookeeper-3.5.9&#x2F;apache-zookeeper-3.5.9-bin.tar.gz\n\n# 确保如下目录存在，不存在就创建\nmkdir -p &#x2F;export&#x2F;server\n\n# 解压\ntar -zxvf apache-zookeeper-3.5.9-bin.tar.gz -C &#x2F;export&#x2F;server\n\n【node1上操作】创建软链接\nln -s &#x2F;export&#x2F;server&#x2F;apache-zookeeper-3.5.9 &#x2F;export&#x2F;server&#x2F;zookeeper\n\n【node1上操作】修改配置文件\nvim &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F;zoo.cfg\n\ntickTime&#x3D;2000\n# zookeeper数据存储目录\ndataDir&#x3D;&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;data\nclientPort&#x3D;2181\ninitLimit&#x3D;5\nsyncLimit&#x3D;2\nserver.1&#x3D;node1:2888:3888\nserver.2&#x3D;node2:2888:3888\nserver.3&#x3D;node3:2888:3888\n\n【node1上操作】配置myid\n# 1. 创建Zookeeper的数据目录\nmkdir &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;data\n\n# 2. 创建文件，并填入1\nvim &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;data&#x2F;myid\n# 在文件内填入1即可\n\n【在node2和node3上操作】，创建文件夹\nmkdir -p &#x2F;export&#x2F;server\n\n【node1上操作】将Zookeeper 复制到node2和node3\ncd &#x2F;export&#x2F;server\n\nscp -r apache-zookeeper-3.5.9 node2:&#96;pwd&#96;&#x2F;\nscp -r apache-zookeeper-3.5.9 node3:&#96;pwd&#96;&#x2F;\n\n【在node2上操作】\n# 1. 创建软链接\nln -s &#x2F;export&#x2F;server&#x2F;apache-zookeeper-3.5.9 &#x2F;export&#x2F;server&#x2F;zookeeper\n\n# 2. 修改myid文件\nvim &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;data&#x2F;myid\n# 修改内容为2\n\n【在node3上操作】\n# 1. 创建软链接\nln -s &#x2F;export&#x2F;server&#x2F;apache-zookeeper-3.5.9 &#x2F;export&#x2F;server&#x2F;zookeeper\n\n# 2. 修改myid文件\nvim &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;data&#x2F;myid\n# 修改内容为3\n\n【在node1、node2、node3上分别执行】启动Zookeeper\n# 启动命令\n&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start\t\t# 启动Zookeeper\n\n【在node1、node2、node3上分别执行】检查Zookeeper进程是否启动\njps\n\n# 结果中找到有：QuorumPeerMain 进程即可\n\n【node1上操作】验证Zookeeper\n&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkCli.sh\n\n# 进入到Zookeeper控制台中后，执行\nls &#x2F;\n\n# 如无报错即配置成功\n\n至此Zookeeper安装完成\nKafka集群安装部署简介Kafka是一款分布式的、去中心化的、高吞吐低延迟、订阅模式的消息队列系统。\n同RabbitMQ一样，Kafka也是消息队列。不过RabbitMQ多用于后端系统，因其更加专注于消息的延迟和容错。\nKafka多用于大数据体系，因其更加专注于数据的吞吐能力。\nKafka多数都是运行在分布式（集群化）模式下，所以课程将以3台服务器，来完成Kafka集群的安装部署。\n安装\n确保已经跟随前面的视频，安装并部署了JDK和Zookeeper服务\n\n\n\n\n\n\n\n\n\nKafka的运行依赖JDK环境和Zookeeper请确保已经有了JDK环境和Zookeeper\n\n【在node1操作】下载并上传Kafka的安装包\n# 下载安装包\nwget http:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;kafka&#x2F;2.4.1&#x2F;kafka_2.12-2.4.1.tgz\n\n【在node1操作】解压\nmkdir -p &#x2F;export&#x2F;server\t\t\t# 此文件夹如果不存在需先创建\n\n# 解压\ntar -zxvf kafka_2.12-2.4.1.tgz -C &#x2F;export&#x2F;server&#x2F;\n\n# 创建软链接\nln -s &#x2F;export&#x2F;server&#x2F;kafka_2.12-2.4.1 &#x2F;export&#x2F;server&#x2F;kafka\n\n【在node1操作】修改Kafka目录内的config目录内的server.properties文件\ncd &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config\n# 指定broker的id\nbroker.id&#x3D;1\n# 指定 kafka的绑定监听的地址\nlisteners&#x3D;PLAINTEXT:&#x2F;&#x2F;node1:9092\n# 指定Kafka数据的位置\nlog.dirs&#x3D;&#x2F;export&#x2F;server&#x2F;kafka&#x2F;data\n# 指定Zookeeper的三个节点\nzookeeper.connect&#x3D;node1:2181,node2:2181,node3:2181\n\n【在node1操作】将node1的kafka复制到node2和node3\ncd &#x2F;export&#x2F;server\n\n# 复制到node2同名文件夹\nscp -r kafka_2.12-2.4.1 node2:&#96;pwd&#96;&#x2F;\n# 复制到node3同名文件夹\nscp -r kafka_2.12-2.4.1 node3:$PWD\n\n【在node2操作】\n# 创建软链接\nln -s &#x2F;export&#x2F;server&#x2F;kafka_2.12-2.4.1 &#x2F;export&#x2F;server&#x2F;kafka\n\ncd &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config\n# 指定broker的id\nbroker.id&#x3D;2\n# 指定 kafka的绑定监听的地址\nlisteners&#x3D;PLAINTEXT:&#x2F;&#x2F;node2:9092\n# 指定Kafka数据的位置\nlog.dirs&#x3D;&#x2F;export&#x2F;server&#x2F;kafka&#x2F;data\n# 指定Zookeeper的三个节点\nzookeeper.connect&#x3D;node1:2181,node2:2181,node3:2181\n\n【在node3操作】\n# 创建软链接\nln -s &#x2F;export&#x2F;server&#x2F;kafka_2.12-2.4.1 &#x2F;export&#x2F;server&#x2F;kafka\n\ncd &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config\n# 指定broker的id\nbroker.id&#x3D;3\n# 指定 kafka的绑定监听的地址\nlisteners&#x3D;PLAINTEXT:&#x2F;&#x2F;node3:9092\n# 指定Kafka数据的位置\nlog.dirs&#x3D;&#x2F;export&#x2F;server&#x2F;kafka&#x2F;data\n# 指定Zookeeper的三个节点\nzookeeper.connect&#x3D;node1:2181,node2:2181,node3:2181\n\n启动kafka\n# 请先确保Zookeeper已经启动了\n\n# 方式1：【前台启动】分别在node1、2、3上执行如下语句\n&#x2F;export&#x2F;server&#x2F;kafka&#x2F;bin&#x2F;kafka-server-start.sh &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config&#x2F;server.properties\n\n# 方式2：【后台启动】分别在node1、2、3上执行如下语句\nnohup &#x2F;export&#x2F;server&#x2F;kafka&#x2F;bin&#x2F;kafka-server-start.sh &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config&#x2F;server.properties 2&gt;&amp;1 &gt;&gt; &#x2F;export&#x2F;server&#x2F;kafka&#x2F;kafka-server.log &amp;\n\n验证Kafka启动\n# 在每一台服务器执行\njps\n\n\n\n\n测试Kafka能否正常使用\n创建测试主题\n\n# 在node1执行，创建一个主题\n&#x2F;export&#x2F;server&#x2F;kafka_2.12-2.4.1&#x2F;bin&#x2F;kafka-topics.sh --create --zookeeper node1:2181 --replication-factor 1 --partitions 3 --topic test\n\n\n运行测试，请在FinalShell中打开2个node1的终端页面\n\n# 打开一个终端页面，启动一个模拟的数据生产者\n&#x2F;export&#x2F;server&#x2F;kafka_2.12-2.4.1&#x2F;bin&#x2F;kafka-console-producer.sh --broker-list node1:9092 --topic test\n# 再打开一个新的终端页面，在启动一个模拟的数据消费者\n&#x2F;export&#x2F;server&#x2F;kafka_2.12-2.4.1&#x2F;bin&#x2F;kafka-console-consumer.sh --bootstrap-server node1:9092 --topic test --from-beginning\n\n\n\n\n\n大数据集群（Hadoop生态）安装部署简介1）Hadoop是一个由Apache基金会所开发的分布式系统基础架构。2）主要解决，海量数据的存储和海量数据的分析计算问题。\nHadoop HDFS 提供分布式海量数据存储能力\nHadoop YARN 提供分布式集群资源管理能力\nHadoop MapReduce 提供分布式海量数据计算能力\n前置要求\n请确保完成了集群化环境前置准备章节的内容\n即：JDK、SSH免密、关闭防火墙、配置主机名映射等前置操作\n\nHadoop集群角色Hadoop生态体系中总共会出现如下进程角色：\n\nHadoop HDFS的管理角色：Namenode进程（仅需1个即可（管理者一个就够））\nHadoop HDFS的工作角色：Datanode进程（需要多个（工人，越多越好，一个机器启动一个））\nHadoop YARN的管理角色：ResourceManager进程（仅需1个即可（管理者一个就够））\nHadoop YARN的工作角色：NodeManager进程（需要多个（工人，越多越好，一个机器启动一个））\nHadoop 历史记录服务器角色：HistoryServer进程（仅需1个即可（功能进程无需太多1个足够））\nHadoop 代理服务器角色：WebProxyServer进程（仅需1个即可（功能进程无需太多1个足够））\nZookeeper的进程：QuorumPeerMain进程（仅需1个即可（Zookeeper的工作者，越多越好））\n\n角色和节点分配角色分配如下：\n\nnode1:Namenode、Datanode、ResourceManager、NodeManager、HistoryServer、WebProxyServer、QuorumPeerMain\nnode2:Datanode、NodeManager、QuorumPeerMain\nnode3:Datanode、NodeManager、QuorumPeerMain\n\n\n安装调整虚拟机内存如上图，可以看出node1承载了太多的压力。同时node2和node3也同时运行了不少程序\n为了确保集群的稳定，需要对虚拟机进行内存设置。\n请在VMware中，对：\n\nnode1设置4GB或以上内存\nnode2和node3设置2GB或以上内存\n\n\n\n\n\n\n\n\n\n\n大数据的软件本身就是集群化（一堆服务器）一起运行的。\n现在我们在一台电脑中以多台虚拟机来模拟集群，确实会有很大的内存压力哦。\nZookeeper集群部署略\nHadoop集群部署\n下载Hadoop安装包、解压、配置软链接\n# 1. 下载\nwget http:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;hadoop&#x2F;common&#x2F;hadoop-3.3.0&#x2F;hadoop-3.3.0.tar.gz\n\n# 2. 解压\n# 请确保目录&#x2F;export&#x2F;server存在\ntar -zxvf hadoop-3.3.0.tar.gz -C &#x2F;export&#x2F;server&#x2F;\n\n# 3. 构建软链接\nln -s &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0 &#x2F;export&#x2F;server&#x2F;hadoop\n\n修改配置文件：hadoop-env.sh\n\n\n\n\n\n\n\n\n\nHadoop的配置文件要修改的地方很多，请细心\ncd 进入到&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop，文件夹中，配置文件都在这里\n修改hadoop-env.sh文件\n\n\n\n\n\n\n\n\n\n此文件是配置一些Hadoop用到的环境变量\n这些是临时变量，在Hadoop运行时有用\n如果要永久生效，需要写到&#x2F;etc&#x2F;profile中\n# 在文件开头加入：\n# 配置Java安装路径\nexport JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk\n# 配置Hadoop安装路径\nexport HADOOP_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop\n# Hadoop hdfs配置文件路径\nexport HADOOP_CONF_DIR&#x3D;$HADOOP_HOME&#x2F;etc&#x2F;hadoop\n# Hadoop YARN配置文件路径\nexport YARN_CONF_DIR&#x3D;$HADOOP_HOME&#x2F;etc&#x2F;hadoop\n# Hadoop YARN 日志文件夹\nexport YARN_LOG_DIR&#x3D;$HADOOP_HOME&#x2F;logs&#x2F;yarn\n# Hadoop hdfs 日志文件夹\nexport HADOOP_LOG_DIR&#x3D;$HADOOP_HOME&#x2F;logs&#x2F;hdfs\n\n# Hadoop的使用启动用户配置\nexport HDFS_NAMENODE_USER&#x3D;root\nexport HDFS_DATANODE_USER&#x3D;root\nexport HDFS_SECONDARYNAMENODE_USER&#x3D;root\nexport YARN_RESOURCEMANAGER_USER&#x3D;root\nexport YARN_NODEMANAGER_USER&#x3D;root\nexport YARN_PROXYSERVER_USER&#x3D;root\n\n修改配置文件：core-site.xml\n如下，清空文件，填入如下内容\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n-->\n\n&lt;!-- Put site-specific property overrides in this file. -->\n&lt;configuration>\n  &lt;property>\n    &lt;name>fs.defaultFS&lt;/name>\n    &lt;value>hdfs://node1:8020&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n  &lt;property>\n    &lt;name>io.file.buffer.size&lt;/name>\n    &lt;value>131072&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n&lt;/configuration>\n\n配置：hdfs-site.xml文件\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n-->\n\n&lt;!-- Put site-specific property overrides in this file. -->\n\n&lt;configuration>\n    &lt;property>\n        &lt;name>dfs.datanode.data.dir.perm&lt;/name>\n        &lt;value>700&lt;/value>\n    &lt;/property>\n\n  &lt;property>\n    &lt;name>dfs.namenode.name.dir&lt;/name>\n    &lt;value>/data/nn&lt;/value>\n    &lt;description>Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently.&lt;/description>\n  &lt;/property>\n\n  &lt;property>\n    &lt;name>dfs.namenode.hosts&lt;/name>\n    &lt;value>node1,node2,node3&lt;/value>\n    &lt;description>List of permitted DataNodes.&lt;/description>\n  &lt;/property>\n\n  &lt;property>\n    &lt;name>dfs.blocksize&lt;/name>\n    &lt;value>268435456&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n\n  &lt;property>\n    &lt;name>dfs.namenode.handler.count&lt;/name>\n    &lt;value>100&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n  &lt;property>\n    &lt;name>dfs.datanode.data.dir&lt;/name>\n    &lt;value>/data/dn&lt;/value>\n  &lt;/property>\n&lt;/configuration>\n\n配置：mapred-env.sh文件\n# 在文件的开头加入如下环境变量设置\nexport JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk\nexport HADOOP_JOB_HISTORYSERVER_HEAPSIZE&#x3D;1000\nexport HADOOP_MAPRED_ROOT_LOGGER&#x3D;INFO,RFA\n\n配置：mapred-site.xml文件\n&lt;?xml version=\"1.0\"?>\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n-->\n\n&lt;!-- Put site-specific property overrides in this file. -->\n\n&lt;configuration>\n  &lt;property>\n    &lt;name>mapreduce.framework.name&lt;/name>\n    &lt;value>yarn&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n  &lt;property>\n    &lt;name>mapreduce.jobhistory.address&lt;/name>\n    &lt;value>node1:10020&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n\n  &lt;property>\n    &lt;name>mapreduce.jobhistory.webapp.address&lt;/name>\n    &lt;value>node1:19888&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n\n  &lt;property>\n    &lt;name>mapreduce.jobhistory.intermediate-done-dir&lt;/name>\n    &lt;value>/data/mr-history/tmp&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n\n  &lt;property>\n    &lt;name>mapreduce.jobhistory.done-dir&lt;/name>\n    &lt;value>/data/mr-history/done&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n&lt;property>\n  &lt;name>yarn.app.mapreduce.am.env&lt;/name>\n  &lt;value>HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value>\n&lt;/property>\n&lt;property>\n  &lt;name>mapreduce.map.env&lt;/name>\n  &lt;value>HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value>\n&lt;/property>\n&lt;property>\n  &lt;name>mapreduce.reduce.env&lt;/name>\n  &lt;value>HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value>\n&lt;/property>\n&lt;/configuration>\n\n配置：yarn-env.sh文件\n# 在文件的开头加入如下环境变量设置\nexport JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk\nexport HADOOP_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop\nexport HADOOP_CONF_DIR&#x3D;$HADOOP_HOME&#x2F;etc&#x2F;hadoop\nexport YARN_CONF_DIR&#x3D;$HADOOP_HOME&#x2F;etc&#x2F;hadoop\nexport YARN_LOG_DIR&#x3D;$HADOOP_HOME&#x2F;logs&#x2F;yarn\nexport HADOOP_LOG_DIR&#x3D;$HADOOP_HOME&#x2F;logs&#x2F;hdfs\n\n配置：yarn-site.xml文件\n&lt;?xml version=\"1.0\"?>\n&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n-->\n&lt;configuration>\n\n&lt;!-- Site specific YARN configuration properties -->\n&lt;property>\n    &lt;name>yarn.log.server.url&lt;/name>\n    &lt;value>http://node1:19888/jobhistory/logs&lt;/value>\n    &lt;description>&lt;/description>\n&lt;/property>\n\n  &lt;property>\n    &lt;name>yarn.web-proxy.address&lt;/name>\n    &lt;value>node1:8089&lt;/value>\n    &lt;description>proxy server hostname and port&lt;/description>\n  &lt;/property>\n\n\n  &lt;property>\n    &lt;name>yarn.log-aggregation-enable&lt;/name>\n    &lt;value>true&lt;/value>\n    &lt;description>Configuration to enable or disable log aggregation&lt;/description>\n  &lt;/property>\n\n  &lt;property>\n    &lt;name>yarn.nodemanager.remote-app-log-dir&lt;/name>\n    &lt;value>/tmp/logs&lt;/value>\n    &lt;description>Configuration to enable or disable log aggregation&lt;/description>\n  &lt;/property>\n\n\n&lt;!-- Site specific YARN configuration properties -->\n  &lt;property>\n    &lt;name>yarn.resourcemanager.hostname&lt;/name>\n    &lt;value>node1&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n  &lt;property>\n    &lt;name>yarn.resourcemanager.scheduler.class&lt;/name>\n    &lt;value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value>\n    &lt;description>&lt;/description>\n  &lt;/property>\n\n  &lt;property>\n    &lt;name>yarn.nodemanager.local-dirs&lt;/name>\n    &lt;value>/data/nm-local&lt;/value>\n    &lt;description>Comma-separated list of paths on the local filesystem where intermediate data is written.&lt;/description>\n  &lt;/property>\n\n\n  &lt;property>\n    &lt;name>yarn.nodemanager.log-dirs&lt;/name>\n    &lt;value>/data/nm-log&lt;/value>\n    &lt;description>Comma-separated list of paths on the local filesystem where logs are written.&lt;/description>\n  &lt;/property>\n\n\n  &lt;property>\n    &lt;name>yarn.nodemanager.log.retain-seconds&lt;/name>\n    &lt;value>10800&lt;/value>\n    &lt;description>Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.&lt;/description>\n  &lt;/property>\n\n\n\n  &lt;property>\n    &lt;name>yarn.nodemanager.aux-services&lt;/name>\n    &lt;value>mapreduce_shuffle&lt;/value>\n    &lt;description>Shuffle service that needs to be set for Map Reduce applications.&lt;/description>\n  &lt;/property>\n&lt;/configuration>\n\n修改workers文件\n# 全部内容如下\nnode1\nnode2\nnode3\n\n分发hadoop到其它机器\n\n\n   # 在node1执行\ncd &#x2F;export&#x2F;server\n\nscp -r hadoop-3.3.0 node2:&#96;pwd&#96;&#x2F;\nscp -r hadoop-3.3.0 node2:&#96;pwd&#96;&#x2F;\n\n\n在node2、node3执行\n# 创建软链接\nln -s &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0 &#x2F;export&#x2F;server&#x2F;hadoop\n\n创建所需目录\n\n在node1执行：\nmkdir -p &#x2F;data&#x2F;nn\nmkdir -p &#x2F;data&#x2F;dn\nmkdir -p &#x2F;data&#x2F;nm-log\nmkdir -p &#x2F;data&#x2F;nm-local\n\n在node2执行：\nmkdir -p &#x2F;data&#x2F;dn\nmkdir -p &#x2F;data&#x2F;nm-log\nmkdir -p &#x2F;data&#x2F;nm-local\n\n在node3执行：\nmkdir -p &#x2F;data&#x2F;dn\nmkdir -p &#x2F;data&#x2F;nm-log\nmkdir -p &#x2F;data&#x2F;nm-local\n\n\n配置环境变量\n在node1、node2、node3修改&#x2F;etc&#x2F;profile\nexport HADOOP_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop\nexport PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin\n\n执行source /etc/profile生效\n\n格式化NameNode，在node1执行\nhadoop namenode -format\n\n\n\n\n\n\n\n\n\n\nhadoop这个命令来自于：$HADOOP_HOME&#x2F;bin中的程序\n由于配置了环境变量PATH，所以可以在任意位置执行hadoop命令哦\n\n启动hadoop的hdfs集群，在node1执行即可\nstart-dfs.sh\n\n# 如需停止可以执行\nstop-dfs.sh\n\n\n\n\n\n\n\n\n\n\nstart-dfs.sh这个命令来自于：$HADOOP_HOME&#x2F;sbin中的程序\n由于配置了环境变量PATH，所以可以在任意位置执行start-dfs.sh命令哦\n\n启动hadoop的yarn集群，在node1执行即可\nstart-yarn.sh\n\n# 如需停止可以执行\nstop-yarn.sh\n\n启动历史服务器\nmapred --daemon start historyserver\n\n# 如需停止将start更换为stop\n\n启动web代理服务器\nyarn-daemon.sh start proxyserver\n\n# 如需停止将start更换为stop\n\n验证Hadoop集群运行情况\n在node1、node2、node3上通过jps验证进程是否都启动成功\n\n验证HDFS，浏览器打开：http://node1:9870\n创建文件test.txt，随意填入内容，并执行：\nhadoop fs -put test.txt &#x2F;test.txt\n\nhadoop fs -cat &#x2F;test.txt\n\n验证YARN，浏览器打开：http://node1:8088\n执行：\n# 创建文件words.txt，填入如下内容\nitheima itcast hadoop\nitheima hadoop hadoop\nitheima itcast\n\n# 将文件上传到HDFS中\nhadoop fs -put words.txt &#x2F;words.txt\n\n# 执行如下命令验证YARN是否正常\nhadoop jar &#x2F;export&#x2F;server&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.3.0.jar wordcount -Dmapred.job.queue.name&#x3D;root.root &#x2F;words.txt &#x2F;output\n\n大数据NoSQL数据库HBase集群部署简介HBase 是一种分布式、可扩展、支持海量数据存储的 NoSQL 数据库。\n和Redis一样，HBase是一款KeyValue型存储的数据库。\n不过和Redis设计方向不同\n\nRedis设计为少量数据，超快检索\nHBase设计为海量数据，快速检索\n\nHBase在大数据领域应用十分广泛，现在我们来在node1、node2、node3上部署HBase集群。\n安装\nHBase依赖Zookeeper、JDK、Hadoop（HDFS），请确保已经完成前面\n\n集群化软件前置准备（JDK）\nZookeeper\nHadoop\n这些环节的软件安装\n\n\n【node1执行】下载HBase安装包\n# 下载\nwget http:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;hbase&#x2F;2.1.0&#x2F;hbase-2.1.0-bin.tar.gz\n\n# 解压\ntar -zxvf hbase-2.1.0-bin.tar.gz -C &#x2F;export&#x2F;server\n\n# 配置软链接\nln -s &#x2F;export&#x2F;server&#x2F;hbase-2.1.0 &#x2F;export&#x2F;server&#x2F;hbase\n\n【node1执行】，修改配置文件，修改conf/hbase-env.sh文件\n# 在28行配置JAVA_HOME\nexport JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk\n# 在126行配置：\n# 意思表示，不使用HBase自带的Zookeeper，而是用独立Zookeeper\nexport HBASE_MANAGES_ZK&#x3D;false\n# 在任意行，比如26行，添加如下内容：\nexport HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP&#x3D;&quot;true&quot;\n\n【node1执行】，修改配置文件，修改conf/hbase-site.xml文件\n# 将文件的全部内容替换成如下内容：\n&lt;configuration&gt;\n        &lt;!-- HBase数据在HDFS中的存放的路径 --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.rootdir&lt;&#x2F;name&gt;\n            &lt;value&gt;hdfs:&#x2F;&#x2F;node1:8020&#x2F;hbase&lt;&#x2F;value&gt;\n        &lt;&#x2F;property&gt;\n        &lt;!-- Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面 --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.cluster.distributed&lt;&#x2F;name&gt;\n            &lt;value&gt;true&lt;&#x2F;value&gt;\n        &lt;&#x2F;property&gt;\n        &lt;!-- ZooKeeper的地址 --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.zookeeper.quorum&lt;&#x2F;name&gt;\n            &lt;value&gt;node1,node2,node3&lt;&#x2F;value&gt;\n        &lt;&#x2F;property&gt;\n        &lt;!-- ZooKeeper快照的存储位置 --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.zookeeper.property.dataDir&lt;&#x2F;name&gt;\n            &lt;value&gt;&#x2F;export&#x2F;server&#x2F;apache-zookeeper-3.6.0-bin&#x2F;data&lt;&#x2F;value&gt;\n        &lt;&#x2F;property&gt;\n        &lt;!--  V2.1版本，在分布式情况下, 设置为false --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;&#x2F;name&gt;\n            &lt;value&gt;false&lt;&#x2F;value&gt;\n        &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n\n【node1执行】，修改配置文件，修改conf/regionservers文件\n# 填入如下内容\nnode1\nnode2\nnode3\n\n【node1执行】，分发hbase到其它机器\nscp -r &#x2F;export&#x2F;server&#x2F;hbase-2.1.0 node2:&#x2F;export&#x2F;server&#x2F;\nscp -r &#x2F;export&#x2F;server&#x2F;hbase-2.1.0 node3:&#x2F;export&#x2F;server&#x2F;\n\n【node2、node3执行】，配置软链接\nln -s &#x2F;export&#x2F;server&#x2F;hbase-2.1.0 &#x2F;export&#x2F;server&#x2F;hbase\n\n【node1、node2、node3执行】，配置环境变量\n# 配置在&#x2F;etc&#x2F;profile内，追加如下两行\nexport HBASE_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;hbase\nexport PATH&#x3D;$HBASE_HOME&#x2F;bin:$PATH\n\nsource &#x2F;etc&#x2F;profile\n\n【node1执行】启动HBase\n\n\n\n\n\n\n\n\n\n请确保：Hadoop HDFS、Zookeeper是已经启动了的\nstart-hbase.sh\n\n# 如需停止可使用\nstop-hbase.sh\n\n\n\n\n\n\n\n\n\n\n由于我们配置了环境变量export PATH&#x3D;$PATH:$HBASE_HOME&#x2F;bin\nstart-hbase.sh即在$HBASE_HOME&#x2F;bin内，所以可以无论当前目录在哪，均可直接执行\n\n验证HBase\n浏览器打开：http://node1:16010，即可看到HBase的WEB UI页面\n\n简单测试使用HBase\n【node1执行】\nhbase shell\n\n# 创建表\ncreate &#39;test&#39;, &#39;cf&#39;\n\n# 插入数据\nput &#39;test&#39;, &#39;rk001&#39;, &#39;cf:info&#39;, &#39;itheima&#39;\n\n# 查询数据\nget &#39;test&#39;, &#39;rk001&#39;\n\n# 扫描表数据\nscan &#39;test&#39;\n\n分布式内存计算Spark环境部署注意本小节的操作，基于：大数据集群（Hadoop生态）安装部署环节中所构建的Hadoop集群\n如果没有Hadoop集群，请参阅前置内容，部署好环境。\n简介Spark是一款分布式内存计算引擎，可以支撑海量数据的分布式计算。\nSpark在大数据体系是明星产品，作为最新一代的综合计算引擎，支持离线计算和实时计算。\n在大数据领域广泛应用，是目前世界上使用最多的大数据分布式计算引擎。\n我们将基于前面构建的Hadoop集群，部署Spark Standalone集群。\n安装\n【node1执行】下载并解压\nwget https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;spark&#x2F;spark-2.4.5&#x2F;spark-2.4.5-bin-hadoop2.7.tgz\n\n# 解压\ntar -zxvf spark-2.4.5-bin-hadoop2.7.tgz -C &#x2F;export&#x2F;server&#x2F;\n\n# 软链接\nln -s &#x2F;export&#x2F;server&#x2F;spark-2.4.5-bin-hadoop2.7 &#x2F;export&#x2F;server&#x2F;spark\n\n【node1执行】修改配置文件名称\n# 改名\ncd &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf\nmv spark-env.sh.template spark-env.sh\nmv slaves.template slaves\n\n【node1执行】修改配置文件，spark-env.sh\n## 设置JAVA安装目录\nJAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk\n\n## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群\nHADOOP_CONF_DIR&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop\nYARN_CONF_DIR&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop\n\n## 指定spark老大Master的IP和提交任务的通信端口\nexport SPARK_MASTER_HOST&#x3D;node1\nexport SPARK_MASTER_PORT&#x3D;7077\n\nSPARK_MASTER_WEBUI_PORT&#x3D;8080\nSPARK_WORKER_CORES&#x3D;1\nSPARK_WORKER_MEMORY&#x3D;1g\n\n【node1执行】修改配置文件，slaves\nnode1\nnode2\nnode3\n\n【node1执行】分发\nscp -r spark-2.4.5-bin-hadoop2.7 node2:$PWD\nscp -r spark-2.4.5-bin-hadoop2.7 node3:$PWD\n\n【node2、node3执行】设置软链接\nln -s &#x2F;export&#x2F;server&#x2F;spark-2.4.5-bin-hadoop2.7 &#x2F;export&#x2F;server&#x2F;spark\n\n【node1执行】启动Spark集群\n&#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;start-all.sh\n\n# 如需停止，可以\n&#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;stop-all.sh\n\n打开Spark监控页面，浏览器打开：http://node1:8081\n\n【node1执行】提交测试任务\n&#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit --master spark:&#x2F;&#x2F;node1:7077 --class org.apache.spark.examples.SparkPi &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;jars&#x2F;spark-examples_2.11-2.4.5.jar\n\n分布式内存计算Flink环境部署注意本小节的操作，基于：大数据集群（Hadoop生态）安装部署环节中所构建的Hadoop集群\n如果没有Hadoop集群，请参阅前置内容，部署好环境。\n简介Flink同Spark一样，是一款分布式内存计算引擎，可以支撑海量数据的分布式计算。\nFlink在大数据体系同样是明星产品，作为最新一代的综合计算引擎，支持离线计算和实时计算。\n在大数据领域广泛应用，是目前世界上除去Spark以外，应用最为广泛的分布式计算引擎。\n我们将基于前面构建的Hadoop集群，部署Flink Standalone集群\nSpark更加偏向于离线计算而Flink更加偏向于实时计算。\n安装\n【node1操作】下载安装包\nwget https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;flink&#x2F;flink-1.10.0&#x2F;flink-1.10.0-bin-scala_2.11.tgz\n\n# 解压\ntar -zxvf flink-1.10.0-bin-scala_2.11.tgz -C &#x2F;export&#x2F;server&#x2F;\n\n# 软链接\nln -s &#x2F;export&#x2F;server&#x2F;flink-1.10.0 &#x2F;export&#x2F;server&#x2F;flink\n\n【node1操作】修改配置文件，conf/flink-conf.yaml\n# jobManager 的IP地址\njobmanager.rpc.address: node1\n# JobManager 的端口号\njobmanager.rpc.port: 6123\n# JobManager JVM heap 内存大小\njobmanager.heap.size: 1024m\n# TaskManager JVM heap 内存大小\ntaskmanager.heap.size: 1024m\n# 每个 TaskManager 提供的任务 slots 数量大小\ntaskmanager.numberOfTaskSlots: 2\n#是否进行预分配内存，默认不进行预分配，这样在我们不使用flink集群时候不会占用集群资源\ntaskmanager.memory.preallocate: false\n# 程序默认并行计算的个数\nparallelism.default: 1\n#JobManager的Web界面的端口（默认：8081）\njobmanager.web.port: 8081\n\n【node1操作】，修改配置文件，conf/slaves\nnode1\nnode2\nnode3\n\n【node1操作】分发Flink安装包到其它机器\ncd &#x2F;export&#x2F;server\nscp -r flink-1.10.0 node2:&#96;pwd&#96;&#x2F;\nscp -r flink-1.10.0 node3:&#96;pwd&#96;&#x2F;\n\n【node2、node3操作】\n# 配置软链接\nln -s &#x2F;export&#x2F;server&#x2F;flink-1.10.0 &#x2F;export&#x2F;server&#x2F;flink\n\n【node1操作】，启动Flink\n&#x2F;export&#x2F;server&#x2F;flink&#x2F;bin&#x2F;start-cluster.sh\n\n验证Flink启动\n# 浏览器打开\nhttp:&#x2F;&#x2F;node1:8081\n\n提交测试任务\n【node1执行】\n&#x2F;export&#x2F;server&#x2F;flink&#x2F;bin&#x2F;flink run &#x2F;export&#x2F;server&#x2F;flink-1.10.0&#x2F;examples&#x2F;batch&#x2F;WordCount.jar\n\n运维监控Zabbix部署简介Zabbix 由 Alexei Vladishev 创建，目前由其成立的公司—— Zabbix SIA 积极的持续开发更新维护， 并为用户提供技术支持服务。\nZabbix 是一个&#x3D;&#x3D;企业级分布式开源监控解决方案&#x3D;&#x3D;。\nZabbix 软件能够&#x3D;&#x3D;监控&#x3D;&#x3D;众多网络参数和服务器的&#x3D;&#x3D;健康度、完整性&#x3D;&#x3D;。Zabbix 使用灵活的告警机制，允许用户为几乎任何事件配置基于邮件的告警。这样用户可以快速响应服务器问题。Zabbix 基于存储的数据提供出色的报表和数据可视化功能。这些功能使得 Zabbix 成为容量规划的理想选择。\n安装\n\n\n\n\n\n\n\n\n 安装整体步骤:\n\n准备Linux 服务器(虚拟机)\n安装Mysql\n安装zabbix( 包含 server  agent  web)\n配置 mysql, 为zabbix创建表结构\n配置zabbix server\n启动并开启开机自启动\n\n\n安装前准备 - Mysql安装ZabbixServer需要先安装好Mysql数据库\n课程使用Mysql 5.7\n安装步骤：\n# 安装Mysql yum库\nrpm -Uvh http:&#x2F;&#x2F;repo.mysql.com&#x2F;&#x2F;mysql57-community-release-el7-7.noarch.rpm\n\n# yum安装Mysql\nyum -y install mysql-community-server\n\n# 启动Mysql设置开机启动\nsystemctl start mysqld\nsystemctl enable mysqld\n\n# 检查Mysql服务状态\nsystemctl status mysqld\n\n# 第一次启动mysql，会在日志文件中生成root用户的一个随机密码，使用下面命令查看该密码\ngrep &#39;temporary password&#39; &#x2F;var&#x2F;log&#x2F;mysqld.log\n\n# 修改root用户密码\nmysql -u root -p -h localhost\nEnter password:\n \nmysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;Root!@#$&#39;;\n\n# 如果你想设置简单密码，需要降低Mysql的密码安全级别\nset global validate_password_policy&#x3D;LOW; # 密码安全级别低\nset global validate_password_length&#x3D;4;\t # 密码长度最低4位即可\n\n# 然后就可以用简单密码了（课程中使用简单密码，为了方便，生产中不要这样）\nALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;root&#39;;\nmysql&gt; grant all privileges on *.* to root@&#39;%&#39; identified by &#39;root&#39;;\n\n\n\n\n\n安装Zabbix Server 和 Zabbix Agent\n\n\n\n\n\n\n\n\n初始安装，我们先安装ZabbixServer以及在Server本机安装Agent。\n打开官网下载页面：https://www.zabbix.com/download?zabbix=4.0&amp;os_distribution=centos&amp;os_version=7&amp;db=mysql\n\n选择对应的版本，然后再下面官网给出了具体的安装命令，使用rpm和yum来进行安装。\n需要有网络。\n以下内容来自官方页面\na. 安装Zabbix yum库documentation\nrpm -Uvh https:&#x2F;&#x2F;repo.zabbix.com&#x2F;zabbix&#x2F;4.0&#x2F;rhel&#x2F;7&#x2F;x86_64&#x2F;zabbix-release-4.0-2.el7.noarch.rpm\nyum clean all\n\nb. 安装Zabbix Server、前端、Agentyum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent\n# 如果只需要安装Agent的话\nyum -y install zabbix-agent\n\nc. 初始化Mysql数据库documentation\n\n\n\n\n\n\n\n\n\n在Mysql中操作\n# 登录Mysql 数据库\nmysql -uroot -pYourPassword\nmysql&gt; create database zabbix character set utf8 collate utf8_bin;\nmysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by &#39;zabbix&#39;;\n# 或者: grant all privileges on zabbix.* to zabbix@&#39;%&#39; identified by &#39;zabbix&#39;;\nmysql&gt; quit;\n\n测试在Zabbix Server服务器上能否远程登录Mysql，如果可以登录继续向下走。\nImport initial schema and data. You will be prompted to enter your newly created password.\n# zcat &#x2F;usr&#x2F;share&#x2F;doc&#x2F;zabbix-server-mysql*&#x2F;create.sql.gz | mysql -uzabbix -p zabbix\n\nd. 为Zabbix Server配置数据库Edit file &#x2F;etc&#x2F;zabbix&#x2F;zabbix_server.conf\nDBPassword&#x3D;password\nDBHost&#x3D;mysql-host-ip-or-hostname\n\ne. 配置Zabbix的PHP前端Edit file /etc/httpd/conf.d/zabbix.conf, uncomment and set the right timezone for you.# php_value date.timezone Asia/Shanghai\nStart Zabbix server and agent processes and make it start at system boot:\nsystemctl restart zabbix-server zabbix-agent httpd # 启动、重启\nsystemctl enable zabbix-server zabbix-agent httpd  # 开机自启\n\nNow your Zabbix server is up and running!\n配置zabbix 前端（WEB UI）打开:http://192.168.88.131/zabbix\n即可进入Zabbix页面，在首次打开的时候，会进入设置页面，如图：\n\n点击下一步，会检查相应的设置是否都正常\n\n如果一切正常，点击下一步。\n配置DB连接\n\n按具体情况填写即可\n配置Server细节\n\n具体配置即可，Name表示这个Zabbix服务的名字，这里起名叫ITHEIMA-TEST\n安装前总结预览\n检查确认没有问题就下一步\n\n配置完成\n\n初始管理员账户Admin密码zabbix\n输入账户密码后，就能进入zabbix页面了。\n如下图：\n\n现在是一个崭新的zabbix等待我们去探索。\n运维监控Grafana部署简介安装部署形式Grafana支持两种部署形式\n\n自行部署, 可以部署在操作系统之上. 自行提供服务器, 域名等.\nGrafana官方托管. 无需安装, 在线注册即可得到一个专属于自己的Grafana, 但是要花钱的. 是一种SaaS服务\n\n我们课程选择方式1\n安装Grafana支持常见的绝大多数操作系统, 如windows mac linux 同时也支持部署在docker中.\n大多数情况下, Grafana都是部署在linux服务器之上. 所以本课程也是基于Linux系统来讲解.\n对windows mac系统 或 docker部署有兴趣的同学, 请参考:  https://grafana.com/grafana/download\n我们部署Grafana可以使用YUM来进行部署.\n# 创建一个文件\nvim &#x2F;etc&#x2F;yum.repos.d&#x2F;grafana.repo\n\n# 将下面的内容复制进去\n[grafana]\nname&#x3D;grafana\nbaseurl&#x3D;https:&#x2F;&#x2F;packages.grafana.com&#x2F;oss&#x2F;rpm\nrepo_gpgcheck&#x3D;1\nenabled&#x3D;1\ngpgcheck&#x3D;1\ngpgkey&#x3D;https:&#x2F;&#x2F;packages.grafana.com&#x2F;gpg.key\nsslverify&#x3D;1\nsslcacert&#x3D;&#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;ca-bundle.crt\n\n# 最后安装\nyum install grafana\n\n\n\n配置说明grafana-server具有许多配置选项，这些选项可以在.ini配置文件中指定，也可以使用环境变量指定。\n\n\n\n\n\n\n\n\n\n Note. Grafana  needs to be restarted for any configuration changes to take effect. \n配置文件注释;符号在.ini文件中全局表示注释 ()\n配置文件路径如果是自己解压安装, 或者自行编译的方式安装, 配置文件在:\n\n默认: $WORKING_DIR/conf/defaults.ini\n自定义:$WORKING_DIR/conf/custom.ini\n自定义配置文件路径可以被参数--config覆盖\n\n\n\n\n\n\n\n\n\n\n对于YUM RPM 安装的方式, 配置文件在: /etc/grafana/grafana.ini\n使用环境变量可以使用以下语法使用环境变量来覆盖配置文件中的所有选项：\nGF_&lt;SectionName&gt;_&lt;KeyName&gt;\n\n其中SectionName是方括号内的文本。一切都应为大写，.应替换为_ 例如，给定以下配置设置：\n# default section\ninstance_name &#x3D; $&#123;HOSTNAME&#125;\n\n[security]\nadmin_user &#x3D; admin\n\n[auth.google]\nclient_secret &#x3D; 0ldS3cretKey\n\nThen you can override them using:\nexport GF_DEFAULT_INSTANCE_NAME&#x3D;my-instance\nexport GF_SECURITY_ADMIN_USER&#x3D;true\t# GF_ 固定 SECURITY 是SectionName ADMIN_USER 是配置的key 转大写 . 转 _\nexport GF_AUTH_GOOGLE_CLIENT_SECRET&#x3D;newS3cretKey\n\n\n\n开始配置Grafana支持使用Sqlite3 Postgresql Mysql这三种数据库作为其元数据的存储.\n我们课程使用Mysql. 和zabbix的元数据mysql共用一个实例\n只需要配置如下内容即可:\n\n并登陆mysql, 执行:\ncreate database grafana CHARACTER SET utf8 COLLATE utf8_general_ci;\n创建Grafana使用的数据库作为元数据存储.\n启动systemctl daemon-reload\nsystemctl start grafana-server\nsystemctl enable grafana-server\n\n\n\n\n\n浏览器打开：http://node1:3000\n默认账户密码：admin&#x2F;admin\n","slug":"Linux系统软件安装","date":"2022-12-05T09:34:14.172Z","categories_index":"Linux","tags_index":"Linux系统软件安装","author_index":"Areay7"},{"id":"b6f03566ceffbd7d08524bfe0927fefc","title":"Springboot + Mybatis-Plus 整合，搭建增删改查接口","content":"配置环境：\nSpringboot：2.4.5          Mybatis-plus：3.4.3.4    jdk：1.8   \n所需依赖pom文件：\n&lt;build&gt;\n    &lt;plugins&gt;\n        &lt;plugin&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;\n            &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt;\n            &lt;version&gt;2.4.5&lt;&#x2F;version&gt;\n        &lt;&#x2F;plugin&gt;\n    &lt;&#x2F;plugins&gt;\n&lt;&#x2F;build&gt;\n\n&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-test&lt;&#x2F;artifactId&gt;\n        &lt;scope&gt;test&lt;&#x2F;scope&gt;\n    &lt;&#x2F;dependency&gt;\n\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt;\n    &lt;scope&gt;compile&lt;&#x2F;scope&gt;\n&lt;&#x2F;dependency&gt;\n\n&lt;dependency&gt;\n    &lt;groupId&gt;com.baomidou&lt;&#x2F;groupId&gt;\n    &lt;artifactId&gt;mybatis-plus-boot-starter&lt;&#x2F;artifactId&gt;\n    &lt;version&gt;3.4.3.4&lt;&#x2F;version&gt;\n&lt;&#x2F;dependency&gt;\n\n&lt;dependency&gt;\n    &lt;groupId&gt;org.projectlombok&lt;&#x2F;groupId&gt;\n    &lt;artifactId&gt;lombok&lt;&#x2F;artifactId&gt;\n    &lt;version&gt;1.18.20&lt;&#x2F;version&gt;\n&lt;&#x2F;dependency&gt;\n\n&lt;dependency&gt;\n    &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt;\n    &lt;artifactId&gt;fastjson&lt;&#x2F;artifactId&gt;\n    &lt;version&gt;1.2.76&lt;&#x2F;version&gt;\n&lt;&#x2F;dependency&gt;\n\n&lt;dependency&gt;\n    &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt;\n    &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt;\n    &lt;scope&gt;runtime&lt;&#x2F;scope&gt;\n&lt;&#x2F;dependency&gt;\n\n&lt;dependency&gt;\n    &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt;\n    &lt;artifactId&gt;druid-spring-boot-starter&lt;&#x2F;artifactId&gt;\n    &lt;version&gt;1.1.23&lt;&#x2F;version&gt;\n&lt;&#x2F;dependency&gt;\n\n&lt;dependency&gt;\n            &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;\n            &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;\n            &lt;scope&gt;test&lt;&#x2F;scope&gt;\n        &lt;&#x2F;dependency&gt;\n\n\n\n第一步：mysql中建表（sound表）\nSET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS &#x3D; 0;\n\nDROP TABLE IF EXISTS sound;CREATE TABLE sound (  id int NOT NULL AUTO_INCREMENT,  xuHao1 bigint DEFAULT NULL,  xuHao2 bigint DEFAULT NULL,  xuHao3 bigint DEFAULT NULL,  xuHao4 bigint DEFAULT NULL,  xuHao5 bigint DEFAULT NULL,  xuHao6 bigint DEFAULT NULL,  xuHao7 bigint DEFAULT NULL,  xuHao8 bigint DEFAULT NULL,  xuHao9 bigint DEFAULT NULL,  xuHao10 bigint DEFAULT NULL,  xuHao11 bigint DEFAULT NULL,  xuHao12 bigint DEFAULT NULL,  PRIMARY KEY (id)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;4 DEFAULT CHARSET&#x3D;utf8mb4 COLLATE&#x3D;utf8mb4_0900_ai_ci;\n\nBEGIN;INSERT INTO sound VALUES (1, 2, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1);INSERT INTO sound VALUES (2, 2, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1);INSERT INTO sound VALUES (3, 2, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1);COMMIT;\nSET FOREIGN_KEY_CHECKS &#x3D; 1;\n第二步：配置 application.yml 文件\nserver:\n  port: 8080\nspring:\n  application:\n    name: sound_velocity_experiment\n  datasource:\n    druid:\n      driver-class-name: com.mysql.cj.jdbc.Driver\n      url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;test?serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;zeroDateTimeBehavior&#x3D;convertToNull&amp;useSSL&#x3D;false&amp;allowPublicKeyRetrieval&#x3D;true\n      username: root\n      password: root\n\nmybatis-plus:\n  configuration:\n    #在映射实体或者属性时，将数据库中表名和字段名中的下划线去掉，按照驼峰命名法映射\n    map-underscore-to-camel-case: false\n    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl\n  global-config:\n    db-config:\n   # 分配id  主键递增(如果没配置，需在对应的实体类中的字段上加入 @TableId(type &#x3D; IdType.AUTO) )\n      id-type: ASSIGN_ID  \n\n\n\n第三步：在 entity 中配置实体类，对应数据库中的表\n@TableName(&quot;sound&quot;)  &#x2F;&#x2F; 对应数据库中的表名\n@AllArgsConstructor  &#x2F;&#x2F; 全参构造器\n@NoArgsConstructor   &#x2F;&#x2F; 无参构造器\n@Data  &#x2F;&#x2F; lombok会自动生成GETTER和SETTER方法\npublic class Sound &#123;\n    private Integer id;\n    private Long xuHao1;\n    private Long xuHao2;\n    private Long xuHao3;\n    private Long xuHao4;\n    private Long xuHao5;\n    private Long xuHao6;\n    private Long xuHao7;\n    private Long xuHao8;\n    private Long xuHao9;\n    private Long xuHao10;\n    private Long xuHao11;\n    private Long xuHao12;\n&#125;\n\n\n\n第四步： 在 Soundmapper 类，操控数据库的地方，继承BaseMapper接口\n&#x2F;**\n * 继承BaseMapper&lt;Sound&gt;接口，相当于帮你写好通用的CRUD方法\n *&#x2F;\n@Mapper\npublic interface  SoundMapper extends BaseMapper&lt;Sound&gt; &#123;&#125;\n\n\n\n第五步： 启动类上加Mapper扫描注解\n@Slf4j\n@MapperScan(&quot;com&#x2F;areay&#x2F;mapper&quot;)  &#x2F;&#x2F; 指定要扫描mapper的位置\n@SpringBootApplication\npublic class SoundVelocityExperimentApplication &#123;\n    public static void main(String[] args) &#123;   SpringApplication.run(SoundVelocityExperimentApplication.class, args);\n        log.info(&quot;项目启动成功...&quot;);\n    &#125;\n&#125;\n\n\n\n第六步：测试类中写入增删改查测试方法\n@SpringBootTest\n@Slf4j\n@DisplayName(&quot;测试mybatis-plus操作&quot;)\nclass SoundVelocityExperimentApplicationTests &#123;\n    &#x2F;**\n     * 注入实体类\n     *&#x2F;\n    @Autowired\n    SoundMapper soundMapper;\n\n    &#x2F;**\n     * 查询所有\n     *&#x2F;\n    @Test\n    void testselectAll()&#123;\n        &#x2F;&#x2F;         查,selectList获取所有的用户信息\n        List&lt;Sound&gt; sounds &#x3D; soundMapper.selectList(null);\n        sounds.forEach(System.out::println);\n    &#125;\n\n    &#x2F;**\n     * 更新方法\n     *&#x2F;\n    @Test\n    void testupDate()&#123;\n        Sound sound &#x3D; new Sound(1, 21L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,12L);\n        int update &#x3D; soundMapper.update(sound, null);\n        System.out.println(update);  &#x2F;&#x2F; 返回1说明更新成功\n    &#125;\n\n\n    &#x2F;**\n     * 插入方法\n     *&#x2F;\n    @Test\n    void testInsert()&#123;\n        Sound sound1 &#x3D; new Sound();\n        sound1.setId(3);\n        sound1.setXuHao1(1L);\n        sound1.setXuHao2(1L);\n        sound1.setXuHao3(1L);\n        sound1.setXuHao4(1L);\n        sound1.setXuHao5(1L);\n        sound1.setXuHao6(1L);\n        sound1.setXuHao7(1L);\n        sound1.setXuHao8(1L);\n        sound1.setXuHao9(1L);\n        sound1.setXuHao10(1L);\n        sound1.setXuHao11(1L);\n        sound1.setXuHao12(1L);\n        int insert &#x3D; soundMapper.insert(sound1);\n&#x2F;&#x2F;        打印日志，方便观察\n        log.info(&quot;insert &#x3D;&gt; &quot; ,insert);\n    &#125;\n\n    &#x2F;**\n     * 删除方法\n     *&#x2F;\n    @Test\n    void testDelete()&#123;\n        int delete &#x3D; soundMapper.deleteById(2);   &#x2F;&#x2F;  指定实体类或者id\n        log.warn(&quot;delete &#x3D;&gt; &quot; , delete);\n    &#125;\n&#125;\n\n\n\n第七步： 在 Controller 类中写入对应的业务\n&#x2F;**\n * 表的控制器\n *&#x2F;\n\n@RestController\n@RequestMapping(&quot;&#x2F;sound&quot;)\npublic class SoundController &#123;\n\n    @Autowired\n    private SoundMapper soundMapper;\n\n\n    &#x2F;**\n     * 返回表中所有用户\n     * @return\n     *&#x2F;\n    @GetMapping\n    public List&lt;Sound&gt; getSounds()&#123;\n        return soundMapper.selectList(null);\n    &#125;\n\n    &#x2F;**\n     * 通过传来的数据，插入用户数据\n     * @param sound\n     * @return\n     *&#x2F;\n    @PostMapping\n    public Boolean saveSound(@RequestBody Sound sound)&#123;\n        int i &#x3D; soundMapper.insert(sound);\n        return i &#x3D;&#x3D; 1;\n    &#125;\n\n    &#x2F;**\n     * 通过传来的数据，更新表\n     * @param sound\n     * @return\n     *&#x2F;\n    @PutMapping\n    public Boolean updateSound(@RequestBody Sound sound)&#123;\n        int update &#x3D; soundMapper.updateById(sound);\n        return update &#x3D;&#x3D; 1;\n    &#125;\n\n    &#x2F;**\n     * 通过用户id删除用户\n     * @param id\n     * @return\n     *&#x2F;\n    @DeleteMapping\n    public Boolean deleteSound(@RequestParam Integer id)&#123;\n        int deleteById &#x3D; soundMapper.deleteById(id);\n        return deleteById &#x3D;&#x3D; 1;\n    &#125;\n&#125;\n\n第八步： 利用 postman 测试对应的接口\n举例 (post请求)     Body -&gt; raw -&gt; JSON ：\n​    {“id”:”3”,\n​    “xuHao1”: “2”,\n​    “xuHao2”: “3”,\n​    “xuHao3”: “4”,\n​    “xuHao4”: “1”,\n​    “xuHao5”: “1”,\n​    “xuHao6”: “1”,\n​    “xuHao7”: “1”,\n​    “xuHao8”: “1”,\n​    “xuHao9”: “1”,\n​    “xuHao10”: “1”,\n​    “xuHao11”: “1”\n​    }\n","slug":"Springboot + Mybatis-Plus 整合，搭建增删改查接口","date":"2022-12-05T09:17:19.750Z","categories_index":"Java","tags_index":"SpringBoot","author_index":"Areay7"},{"id":"c789e22e2887d4e7a6786d624aa250cf","title":"HTML笔记","content":"\n未来记HTML笔记的地方\n\n","slug":"HTML笔记","date":"2022-12-05T09:17:16.939Z","categories_index":"HTML","tags_index":"HTML笔记","author_index":"Areay7"},{"id":"973a8b82181a67edfa77f7da5cc3e192","title":"Css笔记","content":"\n未来记Css笔记的地方\n\n","slug":"Css笔记","date":"2022-12-05T09:17:16.936Z","categories_index":"Css","tags_index":"Css笔记","author_index":"Areay7"},{"id":"c6f5b318c219a3ccc41a24b6ac6ea297","title":"JavaScript笔记","content":"\n未来JavaScript笔记的地方\n\n","slug":"JavaScript笔记","date":"2022-12-05T09:17:16.932Z","categories_index":"JavaScript","tags_index":"JavaScript笔记","author_index":"Areay7"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-12-05T03:04:29.318Z","categories_index":"","tags_index":"","author_index":"Areay7"}]