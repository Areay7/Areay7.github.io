{"title":"Python爬虫","uid":"33e145189cb2c9be32b78fb749fd41d4","slug":"python爬虫","date":"2022-12-10T10:09:28.936Z","updated":"2022-12-10T10:09:23.125Z","comments":true,"path":"api/articles/python爬虫.json","keywords":null,"cover":null,"content":"<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import requests\nfrom bs4 import BeautifulSoup\nimport re\nimport json\nfrom tqdm import tqdm\n\n\nclass CoronaVirusSpider(object):\n\n    def __init__(self):\n        self.home_url &#x3D; &#39;https:&#x2F;&#x2F;ncov.dxy.cn&#x2F;ncovh5&#x2F;view&#x2F;pneumonia&#39;\n\n    def get_content_from_url(self, url):\n        &quot;&quot;&quot;\n        根据url, 获取响应内容的字符串数据\n        :param url: 请求的URL\n        :return: 响应内容的自促穿\n        &quot;&quot;&quot;\n        response &#x3D; requests.get(url)\n        return response.content.decode()\n\n    def parse_home_page(self, home_page, tag_id):\n        &quot;&quot;&quot;\n        解析首页内容,获取解析后的Python数据\n        :param home_page: 首页的内容\n        :return: 解析后的Python数据\n        &quot;&quot;&quot;\n        # 2.从疫情首页,提取最近一日各国疫情数据\n        soup &#x3D; BeautifulSoup(home_page, &#39;html.parser&#39;)\n        script &#x3D; soup.find(id&#x3D;tag_id)\n        text &#x3D; script.text\n        # print(text)\n\n        # 3.从疫情数据中,获取json格式的字符串\n        json_str &#x3D; re.findall(r&#39;\\[.+\\]&#39;, text)[0]\n        # print(json_str)\n\n        # 4.把json格式的字符串转换成Python类型\n        data &#x3D; json.loads(json_str)\n        return data\n\n    def parse_corona_virus(self, last_day_cornoa_virus_of_china, desc):\n        # 定义列表, 用于存储各国从9月1日以来的疫情数据\n        corona_virus &#x3D; []\n        # 2. 遍历各国疫情数据, 获取统计的URL\n        for country in tqdm(last_day_cornoa_virus_of_china, desc):\n\n            # 3. 发送请求, 获取各省疫情json字符串\n            statistics_data_url &#x3D; country[&#39;statisticsData&#39;]\n            statistics_data_json_str &#x3D; self.get_content_from_url(statistics_data_url)\n            # print(statistics_data_json_str)\n\n            # 4.  # 解析各省疫情json字符串, 并添加到列表中\n            statistics_data &#x3D; json.loads(statistics_data_json_str)[&#39;data&#39;]\n            # print(statistics_data)\n            for one_day in statistics_data:\n                one_day[&#39;provinceName&#39;] &#x3D; country[&#39;provinceName&#39;]\n                if country.get(&#39;countryShortCode&#39;):\n                    one_day[&#39;countryShortCode&#39;] &#x3D; country[&#39;countryShortCode&#39;]\n            # print(statistics_data)\n            corona_virus.extend(statistics_data)\n            # print(corona_virus)\n        return corona_virus\n\n    def load(self, path):\n        &quot;&quot;&quot;\n        根据路径, 加载数据\n        :param path:\n        :return:\n        &quot;&quot;&quot;\n        with open(path, encoding&#x3D;&#39;utf-8&#39;) as fp:\n            data &#x3D; json.load(fp)\n        return data\n\n    def save(self, data, path):\n        # 5.把json格式保存,最近一日各国疫情数据\n        with open(path, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;) as fp:\n            json.dump(data, fp, ensure_ascii&#x3D;False)\n\n    def crawl_last_day_corona_virus(self):\n        &quot;&quot;&quot;\n        采集最近一天的各国疫情数据\n        :return:\n        &quot;&quot;&quot;\n        # 1. 发送请求,获取首页内容\n        home_page &#x3D; self.get_content_from_url(self.home_url)\n        # 2. 解析首页内容获取最近一天的各国疫情数据\n        last_day_corona_virus &#x3D; self.parse_home_page(home_page, tag_id&#x3D;&#39;getListByCountryTypeService2true&#39;)\n        # 3. 保存数据\n        self.save(last_day_corona_virus, &#39;..&#x2F;data&#x2F;last_day_corona_virus.json&#39;)\n\n    def crawl_corona_virus(self):\n        &quot;&quot;&quot;\n        采集从9月1日以来各国疫情数据\n        :return:\n        &quot;&quot;&quot;\n        # 1. 加载各国疫情数据\n        last_day_corona_virus &#x3D; self.load(&#39;..&#x2F;data&#x2F;last_day_corona_virus.json&#39;)\n        # print(last_day_corona_virus)\n\n        # 定义列表, 用于存储各国从9月1日以来的疫情数据\n        corona_virus &#x3D; self.parse_corona_virus(last_day_corona_virus, desc&#x3D;&#39;采集9月1日以来的各国疫情信息&#39;)\n\n            # 5. 把列表以json格式保存为文件\n        self.save(corona_virus,&#39;..&#x2F;data&#x2F;corona_virus.json&#39;)\n\n    def crawl_last_day_cornoa_virus_of_china(self):\n        &quot;&quot;&quot;\n        采集最近一日各省疫情数据\n        :return:\n        &quot;&quot;&quot;\n        # 1. 发送请求，获取疫情首页\n        home_page &#x3D; self.get_content_from_url(self.home_url)\n        # 2. 解析疫情首页, 获取最近一日各省份疫情数据\n        last_day_cornoa_virus_of_china &#x3D; self.parse_home_page(home_page,tag_id&#x3D;&#39;getAreaStat&#39;)\n\n        # 3. 保存疫情数据\n        self.save(last_day_cornoa_virus_of_china,&quot;..&#x2F;data&#x2F;last_day_cornoa_virus_of_china.json&quot;)\n\n\n    def crawl_cornoa_virus_of_china(self):\n        &quot;&quot;&quot;\n        采集从9月1日以来的全国个省份的疫情数据\n        :return:\n        &quot;&quot;&quot;\n        # 加载最近一日全国疫情数据\n        last_day_cornoa_virus_of_china &#x3D; self.load(&#39;..&#x2F;data&#x2F;last_day_cornoa_virus_of_china.json&#39;)\n\n        # 遍历最近一日全国疫情数据, 获取各省疫情数据URL\n        corona_virus &#x3D; self.parse_corona_virus(last_day_cornoa_virus_of_china, &#39;采集9月1日以来的各省份疫情信息&#39;)\n\n        # 以json格式保存疫情信息\n        self.save(corona_virus,&#39;..&#x2F;data&#x2F;cornoa_virus_of_china.json&#39;)\n\n\n\n    def run(self):\n        # self.crawl_last_day_corona_virus()\n        self.crawl_corona_virus()\n        # self.crawl_last_day_cornoa_virus_of_china()\n        self.crawl_cornoa_virus_of_china()\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    spider &#x3D; CoronaVirusSpider()\n    spider.run()<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>","feature":true,"text":"import requests from bs4 import BeautifulSoup import re import json from tqdm import tqdm class CoronaVirusSpider(object): def __init__(self...","link":"","photos":[],"count_time":{"symbolsCount":"5.1k","symbolsTime":"5 mins."},"categories":[{"name":"Python","slug":"Python","count":2,"path":"api/categories/Python.json"}],"tags":[{"name":"Python爬虫","slug":"Python爬虫","count":1,"path":"api/tags/Python爬虫.json"}],"toc":"","author":{"name":"Areay7","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"此网站为Areay7的个人博客<Br> 博主为大二物联网工程专业<Br> 物联网工程专业在校生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"Git使用教程","uid":"ee96819a780f88d504f4858a1dcc7bad","slug":"Git教程","date":"2022-12-08T15:59:32.357Z","updated":"2022-12-08T15:59:26.556Z","comments":true,"path":"api/articles/Git教程.json","keywords":null,"cover":[],"text":" # git 教程 [TOC] 1.版本管理工具概念我在大学毕业写论文的时候的时候碰到过如下的现象 &lt;&lt;毕业论文第一版.doc&gt;&gt; &lt;&lt;毕业论文第二版.doc&gt;&gt; &lt;&lt;毕业论文第三版.doc&gt;&gt; &lt;&l...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[{"name":"Git","slug":"Git","count":1,"path":"api/categories/Git.json"}],"tags":[{"name":"Git教程","slug":"Git教程","count":1,"path":"api/tags/Git教程.json"}],"author":{"name":"Areay7","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"此网站为Areay7的个人博客<Br> 博主为大二物联网工程专业<Br> 物联网工程专业在校生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}